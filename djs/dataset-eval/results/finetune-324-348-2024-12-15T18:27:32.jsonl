{"bleu": 0.012760000512022165, "precisions": [0.01744186046511628, 0.013969732246798603, 0.011655011655011656, 0.009334889148191364], "brevity_penalty": 1.0, "length_ratio": 34.4, "translation_length": 860, "reference_length": 25}
{"bleu": 1.9272579049117907e-05, "precisions": [0.6206030150753769, 0.4744341994970662, 0.4110738255033557, 0.36272040302267], "brevity_penalty": 4.210361792859337e-05, "length_ratio": 0.09029038112522686, "translation_length": 1194, "reference_length": 13224}
{"bleu": 0.004136806534754048, "precisions": [0.96440489432703, 0.9276169265033407, 0.8907469342251951, 0.8537946428571429], "brevity_penalty": 0.004554925234240283, "length_ratio": 0.15645666550643927, "translation_length": 899, "reference_length": 5746}
{"bleu": 0.0, "precisions": [0.1, 0.0, 0.0, 0.0], "brevity_penalty": 0.12873490358780418, "length_ratio": 0.32786885245901637, "translation_length": 20, "reference_length": 61}
{"bleu": 0.13938364767555214, "precisions": [0.20029133284777859, 0.141399416909621, 0.12253829321663019, 0.10875912408759124], "brevity_penalty": 1.0, "length_ratio": 3.968208092485549, "translation_length": 1373, "reference_length": 346}
{"bleu": 0.0043219406357046875, "precisions": [0.014134275618374558, 0.00589622641509434, 0.0035419126328217238, 0.001182033096926714], "brevity_penalty": 1.0, "length_ratio": 29.275862068965516, "translation_length": 849, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.25, 0.0, 0.0, 0.0], "brevity_penalty": 5.715007736466731e-07, "length_ratio": 0.06504065040650407, "translation_length": 8, "reference_length": 123}
{"error": "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 218.69 MiB is free. Including non-PyTorch memory, this process has 10.53 GiB memory in use. Of the allocated memory 10.17 GiB is allocated by PyTorch, and 152.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 18.69 MiB is free. Including non-PyTorch memory, this process has 10.72 GiB memory in use. Of the allocated memory 10.36 GiB is allocated by PyTorch, and 158.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.017299784512718026, "precisions": [0.5982062780269058, 0.43177737881508077, 0.42857142857142855, 0.427158273381295], "brevity_penalty": 0.03709880932359339, "length_ratio": 0.23287385129490393, "translation_length": 1115, "reference_length": 4788}
{"bleu": 0.011181125831142067, "precisions": [0.6702937976060935, 0.30718954248366015, 0.23446019629225737, 0.17139737991266377], "brevity_penalty": 0.03707228048472527, "length_ratio": 0.2328350646060299, "translation_length": 919, "reference_length": 3947}
{"bleu": 0.003953217797446228, "precisions": [0.6022988505747127, 0.23475258918296893, 0.2108294930875576, 0.18685121107266436], "brevity_penalty": 0.014470659187626553, "length_ratio": 0.19099890230515917, "translation_length": 870, "reference_length": 4555}
{"bleu": 0.0, "precisions": [0.2, 0.0, 0.0, 0.0], "brevity_penalty": 0.00016658581098763324, "length_ratio": 0.10309278350515463, "translation_length": 10, "reference_length": 97}
{"bleu": 0.6612986223656377, "precisions": [0.6618625277161863, 0.6614872364039955, 0.6611111111111111, 0.660734149054505], "brevity_penalty": 1.0, "length_ratio": 1.4933774834437086, "translation_length": 902, "reference_length": 604}
{"bleu": 0.0, "precisions": [0.043968432919954906, 0.001128668171557562, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 8.696078431372548, "translation_length": 887, "reference_length": 102}
{"bleu": 0.0, "precisions": [0.12, 0.0, 0.0, 0.0], "brevity_penalty": 0.027323722447292545, "length_ratio": 0.21739130434782608, "translation_length": 25, "reference_length": 115}
{"bleu": 0.0, "precisions": [0.04918032786885246, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.265734265734266, "translation_length": 610, "reference_length": 143}
{"bleu": 0.01730497086270937, "precisions": [0.1639111950873878, 0.06805293005671077, 0.054373522458628844, 0.05250709555345317], "brevity_penalty": 0.2303592441679405, "length_ratio": 0.4051674641148325, "translation_length": 2117, "reference_length": 5225}
{"bleu": 0.0009090956851161612, "precisions": [0.282336578581363, 0.06406685236768803, 0.03626220362622036, 0.013966480446927373], "brevity_penalty": 0.016524341822649904, "length_ratio": 0.1959662033251567, "translation_length": 719, "reference_length": 3669}
{"bleu": 0.0, "precisions": [0.3018292682926829, 0.12366412213740458, 0.022935779816513763, 0.0], "brevity_penalty": 5.856186569527315e-05, "length_ratio": 0.0930628457937296, "translation_length": 656, "reference_length": 7049}
{"bleu": 0.017327467165611076, "precisions": [0.23294346978557504, 0.02829268292682927, 0.0185546875, 0.009775171065493646], "brevity_penalty": 0.5240339375668694, "length_ratio": 0.6074600355239786, "translation_length": 1026, "reference_length": 1689}
{"bleu": 0.0, "precisions": [0.23809523809523808, 0.0, 0.0, 0.0], "brevity_penalty": 2.4861831257874807e-06, "length_ratio": 0.07191780821917808, "translation_length": 21, "reference_length": 292}
{"bleu": 2.7939895525503848e-05, "precisions": [0.7, 0.3877551020408163, 0.375, 0.3617021276595745], "brevity_penalty": 6.378452193155948e-05, "length_ratio": 0.09380863039399624, "translation_length": 50, "reference_length": 533}
{"error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"}
