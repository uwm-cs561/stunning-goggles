{"bleu": 0.0, "precisions": [0.05183585313174946, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 7.291338582677166, "translation_length": 926, "reference_length": 127}
{"bleu": 0.0, "precisions": [0.3181818181818182, 0.0, 0.0, 0.0], "brevity_penalty": 9.249795720916071e-06, "length_ratio": 0.07942238267148015, "translation_length": 22, "reference_length": 277}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 19.523809523809526, "translation_length": 2050, "reference_length": 105}
{"bleu": 0.21780195099221325, "precisions": [0.22007722007722008, 0.218568665377176, 0.21705426356589147, 0.21553398058252426], "brevity_penalty": 1.0, "length_ratio": 4.2809917355371905, "translation_length": 518, "reference_length": 121}
{"bleu": 0.0, "precisions": [0.15, 0.0, 0.0, 0.0], "brevity_penalty": 0.2865047968601901, "length_ratio": 0.4444444444444444, "translation_length": 20, "reference_length": 45}
{"bleu": 0.3161188859985317, "precisions": [0.36661698956780925, 0.30895522388059704, 0.29895366218236175, 0.2949101796407186], "brevity_penalty": 1.0, "length_ratio": 1.5112612612612613, "translation_length": 671, "reference_length": 444}
{"error": "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 136.69 MiB is free. Including non-PyTorch memory, this process has 10.61 GiB memory in use. Of the allocated memory 10.27 GiB is allocated by PyTorch, and 131.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 36.69 MiB is free. Including non-PyTorch memory, this process has 10.71 GiB memory in use. Of the allocated memory 10.40 GiB is allocated by PyTorch, and 99.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.05263157894736842, 0.0, 0.0, 0.0], "brevity_penalty": 0.005753800207388146, "length_ratio": 0.1623931623931624, "translation_length": 19, "reference_length": 117}
{"bleu": 0.23710642410780072, "precisions": [0.9970472440944882, 0.9950738916256158, 0.9940828402366864, 0.9930898321816387], "brevity_penalty": 0.23834046123821676, "length_ratio": 0.4108370400323494, "translation_length": 1016, "reference_length": 2473}
{"bleu": 0.0, "precisions": [0.010815307820299502, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 27.953488372093023, "translation_length": 1202, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.15789473684210525, 0.0, 0.0, 0.0], "brevity_penalty": 0.008766285528368277, "length_ratio": 0.1743119266055046, "translation_length": 19, "reference_length": 109}
{"bleu": 1.6388109718151197e-05, "precisions": [0.9711729622266402, 0.8766169154228856, 0.8296812749003984, 0.7826520438683948], "brevity_penalty": 1.9005629220554216e-05, "length_ratio": 0.08424049572935857, "translation_length": 1006, "reference_length": 11942}
{"bleu": 0.023509576662750265, "precisions": [0.05942857142857143, 0.021739130434782608, 0.01718213058419244, 0.013761467889908258], "brevity_penalty": 1.0, "length_ratio": 5.645161290322581, "translation_length": 875, "reference_length": 155}
{"bleu": 0.0037066488629248413, "precisions": [0.010721944245889922, 0.004291845493562232, 0.002863278453829635, 0.0014326647564469914], "brevity_penalty": 1.0, "length_ratio": 24.54385964912281, "translation_length": 1399, "reference_length": 57}
{"bleu": 0.0, "precisions": [0.14285714285714285, 0.0, 0.0, 0.0], "brevity_penalty": 0.03243324089479551, "length_ratio": 0.22580645161290322, "translation_length": 21, "reference_length": 93}
{"bleu": 0.12378586480311624, "precisions": [0.4625935162094763, 0.2833957553058677, 0.23, 0.20525657071339173], "brevity_penalty": 0.4413332092894863, "length_ratio": 0.5500685871056241, "translation_length": 802, "reference_length": 1458}
{"bleu": 0.02319083975912523, "precisions": [0.17575757575757575, 0.06875631951466127, 0.06477732793522267, 0.060790273556231005], "brevity_penalty": 0.2792193582593762, "length_ratio": 0.4394141145139814, "translation_length": 990, "reference_length": 2253}
{"bleu": 0.3805335055352986, "precisions": [0.7615894039735099, 0.5663129973474801, 0.5258964143426295, 0.4853723404255319], "brevity_penalty": 0.6606245943326371, "length_ratio": 0.7069288389513109, "translation_length": 755, "reference_length": 1068}
{"bleu": 0.0, "precisions": [0.05364511691884457, 0.011019283746556474, 0.0, 0.0], "brevity_penalty": 0.002579628090868572, "length_ratio": 0.14367588932806324, "translation_length": 727, "reference_length": 5060}
{"bleu": 2.102272535042146e-05, "precisions": [0.996822033898305, 0.9936373276776246, 0.9915074309978769, 0.9893730074388948], "brevity_penalty": 2.1174522573067607e-05, "length_ratio": 0.08501440922190202, "translation_length": 944, "reference_length": 11104}
{"bleu": 0.0, "precisions": [0.022988505747126436, 0.009868421052631578, 0.004942339373970346, 0.0], "brevity_penalty": 1.0, "length_ratio": 14.853658536585366, "translation_length": 609, "reference_length": 41}
{"bleu": 0.0, "precisions": [0.011916583912611719, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 23.976190476190474, "translation_length": 1007, "reference_length": 42}
{"bleu": 0.02762004556384654, "precisions": [0.0642939150401837, 0.02528735632183908, 0.020713463751438434, 0.01728110599078341], "brevity_penalty": 1.0, "length_ratio": 6.311594202898551, "translation_length": 871, "reference_length": 138}
{"bleu": 0.0, "precisions": [0.602803738317757, 0.0011695906432748538, 0.0, 0.0], "brevity_penalty": 2.683775388877991e-05, "length_ratio": 0.08676261909588485, "translation_length": 856, "reference_length": 9866}
{"bleu": 0.0, "precisions": [0.30472103004291845, 0.0, 0.0, 0.0], "brevity_penalty": 0.6898751531725069, "length_ratio": 0.729264475743349, "translation_length": 932, "reference_length": 1278}
{"error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 270.69 MiB is free. Including non-PyTorch memory, this process has 10.48 GiB memory in use. Of the allocated memory 10.00 GiB is allocated by PyTorch, and 275.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 30.69 MiB is free. Including non-PyTorch memory, this process has 10.71 GiB memory in use. Of the allocated memory 10.29 GiB is allocated by PyTorch, and 219.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 234.69 MiB is free. Including non-PyTorch memory, this process has 10.51 GiB memory in use. Of the allocated memory 10.02 GiB is allocated by PyTorch, and 289.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 34.69 MiB is free. Including non-PyTorch memory, this process has 10.71 GiB memory in use. Of the allocated memory 10.21 GiB is allocated by PyTorch, and 302.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.03003505254184306, "precisions": [0.05520833333333333, 0.03128258602711158, 0.025052192066805846, 0.018808777429467086], "brevity_penalty": 1.0, "length_ratio": 10.786516853932584, "translation_length": 960, "reference_length": 89}
{"bleu": 0.0, "precisions": [0.15384615384615385, 0.0, 0.0, 0.0], "brevity_penalty": 1.3259858681472e-05, "length_ratio": 0.08176100628930817, "translation_length": 13, "reference_length": 159}
{"bleu": 0.09239447333792435, "precisions": [0.12762237762237763, 0.08756567425569177, 0.0824561403508772, 0.07908611599297012], "brevity_penalty": 1.0, "length_ratio": 3.575, "translation_length": 572, "reference_length": 160}
{"bleu": 0.0, "precisions": [0.23529411764705882, 0.0, 0.0, 0.0], "brevity_penalty": 4.3189744300836694e-13, "length_ratio": 0.033932135728542916, "translation_length": 17, "reference_length": 501}
{"bleu": 0.0008294797506577631, "precisions": [0.75, 0.6857142857142857, 0.6470588235294118, 0.6060606060606061], "brevity_penalty": 0.0012377693329126938, "length_ratio": 0.1299638989169675, "translation_length": 36, "reference_length": 277}
{"bleu": 0.0, "precisions": [0.003499562554680665, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 63.5, "translation_length": 1143, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.18181818181818182, 0.0, 0.0, 0.0], "brevity_penalty": 0.3849870989234837, "length_ratio": 0.5116279069767442, "translation_length": 22, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.0037285607755406414, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 74.5, "translation_length": 1341, "reference_length": 18}
{"bleu": 0.06737746795861518, "precisions": [0.0784741144414169, 0.0697928026172301, 0.06382978723404255, 0.05895196506550218], "brevity_penalty": 1.0, "length_ratio": 3.1529209621993126, "translation_length": 1835, "reference_length": 582}
{"bleu": 3.0930610029701715e-57, "precisions": [0.8333333333333334, 0.7142857142857143, 0.6764705882352942, 0.6363636363636364], "brevity_penalty": 4.3473763398885453e-57, "length_ratio": 0.0076465590484282074, "translation_length": 36, "reference_length": 4708}
{"bleu": 0.0, "precisions": [0.0024962556165751375, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 69.06896551724138, "translation_length": 2003, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.15789473684210525, 0.0, 0.0, 0.0], "brevity_penalty": 0.5907775139012316, "length_ratio": 0.6551724137931034, "translation_length": 19, "reference_length": 29}
{"bleu": 0.2918505938238597, "precisions": [0.400679117147708, 0.304421768707483, 0.26405451448040884, 0.22525597269624573], "brevity_penalty": 1.0, "length_ratio": 1.5259067357512954, "translation_length": 589, "reference_length": 386}
{"bleu": 0.0, "precisions": [0.031598513011152414, 0.0037209302325581397, 0.00186219739292365, 0.0], "brevity_penalty": 1.0, "length_ratio": 14.346666666666666, "translation_length": 1076, "reference_length": 75}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.2352941176470589, "translation_length": 21, "reference_length": 17}
{"bleu": 0.0, "precisions": [0.1891891891891892, 0.0, 0.0, 0.0], "brevity_penalty": 0.5088125121973882, "length_ratio": 0.5967741935483871, "translation_length": 37, "reference_length": 62}
{"bleu": 0.0, "precisions": [0.12258064516129032, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.9135802469135803, "translation_length": 155, "reference_length": 81}
{"bleu": 0.0, "precisions": [0.0625, 0.0, 0.0, 0.0], "brevity_penalty": 0.2096113871510978, "length_ratio": 0.3902439024390244, "translation_length": 16, "reference_length": 41}
{"bleu": 0.5161589181818746, "precisions": [0.9488636363636364, 0.9314285714285714, 0.9195402298850575, 0.9075144508670521], "brevity_penalty": 0.5569792612305547, "length_ratio": 0.6308243727598566, "translation_length": 176, "reference_length": 279}
{"bleu": 0.09773805512913322, "precisions": [0.1406926406926407, 0.10725893824485373, 0.08568329718004339, 0.07057546145494029], "brevity_penalty": 1.0, "length_ratio": 5.848101265822785, "translation_length": 924, "reference_length": 158}
{"bleu": 0.0, "precisions": [0.06666666666666667, 0.0, 0.0, 0.0], "brevity_penalty": 0.6703200460356393, "length_ratio": 0.7142857142857143, "translation_length": 15, "reference_length": 21}
{"bleu": 0.0, "precisions": [0.15384615384615385, 0.0, 0.0, 0.0], "brevity_penalty": 0.32361358035074045, "length_ratio": 0.46987951807228917, "translation_length": 39, "reference_length": 83}
{"bleu": 0.07189063174435464, "precisions": [0.09933774834437085, 0.06778797145769623, 0.06425293217746048, 0.06173469387755102], "brevity_penalty": 1.0, "length_ratio": 1.1761533852606352, "translation_length": 1963, "reference_length": 1669}
{"bleu": 0.0, "precisions": [0.0004878048780487805, 0.0, 0.0, 0.0], "brevity_penalty": 0.021109147946541895, "length_ratio": 0.20584396023697157, "translation_length": 2050, "reference_length": 9959}
{"bleu": 0.005463158484414075, "precisions": [0.813953488372093, 0.7421875, 0.7086614173228346, 0.6746031746031746], "brevity_penalty": 0.007452357853939362, "length_ratio": 0.16951379763469118, "translation_length": 129, "reference_length": 761}
{"error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"}
