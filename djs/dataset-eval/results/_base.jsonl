{"bleu": 0.0, "precisions": [0.05732484076433121, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 5.064516129032258, "translation_length": 157, "reference_length": 31}
{"bleu": 0.0, "precisions": [0.008705114254624592, 0.002178649237472767, 0.0010905125408942203, 0.0], "brevity_penalty": 1.0, "length_ratio": 51.05555555555556, "translation_length": 919, "reference_length": 18}
{"bleu": 0.3310266858941486, "precisions": [0.41935483870967744, 0.3352941176470588, 0.30383480825958703, 0.28106508875739644], "brevity_penalty": 1.0, "length_ratio": 1.926553672316384, "translation_length": 341, "reference_length": 177}
{"bleu": 0.180351456848429, "precisions": [0.25384615384615383, 0.17829457364341086, 0.15625, 0.14960629921259844], "brevity_penalty": 1.0, "length_ratio": 2.3636363636363638, "translation_length": 130, "reference_length": 55}
{"bleu": 0.0, "precisions": [0.09740840035746202, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.802575107296137, "translation_length": 1119, "reference_length": 233}
{"bleu": 0.0002783357270224434, "precisions": [0.567741935483871, 0.44155844155844154, 0.43790849673202614, 0.4342105263157895], "brevity_penalty": 0.0005956802955925513, "length_ratio": 0.11868300153139356, "translation_length": 155, "reference_length": 1306}
{"error": "CUDA out of memory. Tried to allocate 336.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 224.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Process 10113 has 288.00 MiB memory in use. Including non-PyTorch memory, this process has 9.65 GiB memory in use. Of the allocated memory 9.19 GiB is allocated by PyTorch, and 259.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0845449002318124, "precisions": [0.18032786885245902, 0.07692307692307693, 0.06629834254143646, 0.05555555555555555], "brevity_penalty": 1.0, "length_ratio": 2.506849315068493, "translation_length": 183, "reference_length": 73}
{"bleu": 0.25270894865101745, "precisions": [0.2736318407960199, 0.255, 0.24623115577889448, 0.23737373737373738], "brevity_penalty": 1.0, "length_ratio": 2.9130434782608696, "translation_length": 201, "reference_length": 69}
{"bleu": 4.383162891760954e-05, "precisions": [0.8620178041543026, 0.799405646359584, 0.7872023809523809, 0.7764530551415797], "brevity_penalty": 5.440844931226456e-05, "length_ratio": 0.09243006034009874, "translation_length": 674, "reference_length": 7292}
{"bleu": 0.02823941578002624, "precisions": [0.03254769921436588, 0.029213483146067417, 0.02699662542182227, 0.024774774774774775], "brevity_penalty": 1.0, "length_ratio": 24.08108108108108, "translation_length": 891, "reference_length": 37}
{"bleu": 0.0, "precisions": [0.22033898305084745, 0.017241379310344827, 0.0, 0.0], "brevity_penalty": 1.7307114635262724e-45, "length_ratio": 0.009609120521172639, "translation_length": 59, "reference_length": 6140}
{"error": "CUDA out of memory. Tried to allocate 184.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 152.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Process 10113 has 288.00 MiB memory in use. Process 774124 has 154.00 MiB memory in use. Including non-PyTorch memory, this process has 9.57 GiB memory in use. Of the allocated memory 9.11 GiB is allocated by PyTorch, and 264.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.005570676931976106, "precisions": [0.012761020881670533, 0.006968641114982578, 0.004651162790697674, 0.002328288707799767], "brevity_penalty": 1.0, "length_ratio": 47.888888888888886, "translation_length": 862, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.022598870056497175, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 8.428571428571429, "translation_length": 177, "reference_length": 21}
{"bleu": 0.0, "precisions": [0.14754098360655737, 0.0, 0.0, 0.0], "brevity_penalty": 2.1650558649969064e-09, "length_ratio": 0.04773082942097027, "translation_length": 61, "reference_length": 1278}
{"bleu": 0.0, "precisions": [0.17647058823529413, 0.0, 0.0, 0.0], "brevity_penalty": 5.966131892809255e-06, "length_ratio": 0.07674943566591422, "translation_length": 34, "reference_length": 443}
{"bleu": 0.020248295673612002, "precisions": [0.044444444444444446, 0.01832460732984293, 0.015727391874180863, 0.013123359580052493], "brevity_penalty": 1.0, "length_ratio": 9.5625, "translation_length": 765, "reference_length": 80}
{"bleu": 0.18149377889760435, "precisions": [0.1842696629213483, 0.18243243243243243, 0.18058690744920994, 0.17873303167420815], "brevity_penalty": 1.0, "length_ratio": 5.0, "translation_length": 445, "reference_length": 89}
{"bleu": 0.6786816667958169, "precisions": [0.9892857142857143, 0.9868891537544696, 0.986873508353222, 0.986857825567503], "brevity_penalty": 0.6872892787909722, "length_ratio": 0.7272727272727273, "translation_length": 840, "reference_length": 1155}
{"bleu": 9.750093646442835e-10, "precisions": [0.891566265060241, 0.8170731707317073, 0.8148148148148148, 0.8125], "brevity_penalty": 1.1699965226432311e-09, "length_ratio": 0.04636871508379888, "translation_length": 83, "reference_length": 1790}
{"bleu": 0.035714030367998875, "precisions": [0.03722854188210962, 0.036231884057971016, 0.035233160621761656, 0.03423236514522822], "brevity_penalty": 1.0, "length_ratio": 22.488372093023255, "translation_length": 967, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 9.428571428571429, "translation_length": 66, "reference_length": 7}
{"bleu": 0.1331926984596854, "precisions": [0.1349206349206349, 0.1337748344370861, 0.13262599469496023, 0.13147410358565736], "brevity_penalty": 1.0, "length_ratio": 7.411764705882353, "translation_length": 756, "reference_length": 102}
{"bleu": 0.0, "precisions": [0.08163265306122448, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.130434782608696, "translation_length": 98, "reference_length": 46}
{"error": "Unsloth: input length 144544 + max_new_tokens 1024 exceeds the maximum sequence length of 131072!\nYou will need to do long context extension by increasing the `max_seq_length` in `FastLanguageModel.from_pretrained`."}
{"bleu": 6.428748016037869e-06, "precisions": [0.5877944325481799, 0.39228295819935693, 0.37553648068669526, 0.3727175080558539], "brevity_penalty": 1.5167436813680673e-05, "length_ratio": 0.08266949902637635, "translation_length": 934, "reference_length": 11298}
{"bleu": 0.0, "precisions": [0.010660980810234541, 0.0032017075773745998, 0.0010683760683760685, 0.0], "brevity_penalty": 1.0, "length_ratio": 52.111111111111114, "translation_length": 938, "reference_length": 18}
{"bleu": 0.019343103471009766, "precisions": [0.050156739811912224, 0.01778242677824268, 0.013612565445026177, 0.011530398322851153], "brevity_penalty": 1.0, "length_ratio": 7.141791044776119, "translation_length": 957, "reference_length": 134}
{"bleu": 0.0, "precisions": [0.2350674373795761, 0.013500482160077145, 0.0028957528957528956, 0.0], "brevity_penalty": 0.2871956689561575, "length_ratio": 0.44492070295756536, "translation_length": 1038, "reference_length": 2333}
{"bleu": 0.03219214626711518, "precisions": [0.034926470588235295, 0.03314917127071823, 0.03136531365313653, 0.029574861367837338], "brevity_penalty": 1.0, "length_ratio": 20.923076923076923, "translation_length": 544, "reference_length": 26}
{"bleu": 0.0, "precisions": [0.33242506811989103, 0.08469945355191257, 0.03561643835616438, 0.0], "brevity_penalty": 0.6772967463903643, "length_ratio": 0.7196078431372549, "translation_length": 367, "reference_length": 510}
{"bleu": 0.018641006964908044, "precisions": [0.5943877551020408, 0.4092071611253197, 0.35384615384615387, 0.30077120822622105], "brevity_penalty": 0.04647328948909084, "length_ratio": 0.2457680250783699, "translation_length": 392, "reference_length": 1595}
{"bleu": 0.01760443275066249, "precisions": [0.02190580503833516, 0.01864035087719298, 0.01646542261251372, 0.014285714285714285], "brevity_penalty": 1.0, "length_ratio": 33.81481481481482, "translation_length": 913, "reference_length": 27}
{"bleu": 0.0, "precisions": [0.006054490413723511, 0.00202020202020202, 0.0010111223458038423, 0.0], "brevity_penalty": 1.0, "length_ratio": 55.05555555555556, "translation_length": 991, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.15865384615384615, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.7478991596638656, "translation_length": 208, "reference_length": 119}
{"bleu": 6.816091530830072e-06, "precisions": [0.6619718309859155, 0.45714285714285713, 0.391304347826087, 0.36764705882352944], "brevity_penalty": 1.492196818001678e-05, "length_ratio": 0.08255813953488372, "translation_length": 71, "reference_length": 860}
{"bleu": 0.02925664410503512, "precisions": [0.116751269035533, 0.022900763358778626, 0.017857142857142856, 0.015345268542199489], "brevity_penalty": 1.0, "length_ratio": 3.3675213675213675, "translation_length": 394, "reference_length": 117}
{"bleu": 3.25308905903359e-17, "precisions": [0.29411764705882354, 0.09523809523809523, 0.060240963855421686, 0.036585365853658534], "brevity_penalty": 3.6699756138485626e-16, "length_ratio": 0.027366387636831937, "translation_length": 85, "reference_length": 3106}
{"bleu": 0.0, "precisions": [0.06321839080459771, 0.011560693641618497, 0.005813953488372093, 0.0], "brevity_penalty": 1.0, "length_ratio": 9.666666666666666, "translation_length": 174, "reference_length": 18}
{"bleu": 0.19332259560157017, "precisions": [0.7206703910614525, 0.6573033707865169, 0.6497175141242938, 0.6477272727272727], "brevity_penalty": 0.28931955829951655, "length_ratio": 0.4463840399002494, "translation_length": 179, "reference_length": 401}
{"bleu": 0.0, "precisions": [0.014925373134328358, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 22.333333333333332, "translation_length": 737, "reference_length": 33}
{"bleu": 0.03392248395284241, "precisions": [0.035453597497393116, 0.03444676409185804, 0.03343782654127482, 0.032426778242677826], "brevity_penalty": 1.0, "length_ratio": 23.390243902439025, "translation_length": 959, "reference_length": 41}
{"bleu": 0.0, "precisions": [0.0827250608272506, 0.014634146341463415, 0.007334963325183374, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.9782608695652173, "translation_length": 411, "reference_length": 138}
{"bleu": 0.03147379442129676, "precisions": [0.03333333333333333, 0.0316930775646372, 0.030884808013355594, 0.03007518796992481], "brevity_penalty": 1.0, "length_ratio": 26.08695652173913, "translation_length": 1200, "reference_length": 46}
{"bleu": 0.015284919243299645, "precisions": [0.017857142857142856, 0.01564245810055866, 0.0145413870246085, 0.013437849944008958], "brevity_penalty": 1.0, "length_ratio": 40.72727272727273, "translation_length": 896, "reference_length": 22}
{"bleu": 0.0677876356520075, "precisions": [0.07423580786026202, 0.06783369803063458, 0.06578947368421052, 0.06373626373626373], "brevity_penalty": 1.0, "length_ratio": 11.743589743589743, "translation_length": 458, "reference_length": 39}
{"bleu": 0.0, "precisions": [0.19047619047619047, 0.0, 0.0, 0.0], "brevity_penalty": 6.026679864946694e-98, "length_ratio": 0.0044472681067344345, "translation_length": 21, "reference_length": 4722}
{"bleu": 0.15194128189188116, "precisions": [0.16137566137566137, 0.15119363395225463, 0.14893617021276595, 0.14666666666666667], "brevity_penalty": 1.0, "length_ratio": 5.815384615384615, "translation_length": 378, "reference_length": 65}
{"bleu": 0.0, "precisions": [0.004305705059203444, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.621890547263682, "translation_length": 929, "reference_length": 201}
{"bleu": 0.021763495332199016, "precisions": [0.7591836734693878, 0.5081967213114754, 0.41975308641975306, 0.38016528925619836], "brevity_penalty": 0.04369103944643397, "length_ratio": 0.24209486166007904, "translation_length": 245, "reference_length": 1012}
{"bleu": 0.31714971594369484, "precisions": [0.32211538461538464, 0.3188405797101449, 0.3155339805825243, 0.3121951219512195], "brevity_penalty": 1.0, "length_ratio": 2.7733333333333334, "translation_length": 208, "reference_length": 75}
{"bleu": 0.010914478922266735, "precisions": [0.032388663967611336, 0.010131712259371834, 0.007099391480730223, 0.006091370558375634], "brevity_penalty": 1.0, "length_ratio": 8.666666666666666, "translation_length": 988, "reference_length": 114}
{"bleu": 0.06730450081803102, "precisions": [0.10453400503778337, 0.06683480453972257, 0.05808080808080808, 0.05056890012642225], "brevity_penalty": 1.0, "length_ratio": 3.497797356828194, "translation_length": 794, "reference_length": 227}
{"bleu": 0.10295802182884511, "precisions": [0.20164609053497942, 0.10743801652892562, 0.08298755186721991, 0.0625], "brevity_penalty": 1.0, "length_ratio": 1.2925531914893618, "translation_length": 243, "reference_length": 188}
{"bleu": 0.0, "precisions": [0.007142857142857143, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 28.823529411764707, "translation_length": 980, "reference_length": 34}
{"bleu": 0.03558848547254283, "precisions": [0.08666666666666667, 0.03355704697986577, 0.02702702702702703, 0.02040816326530612], "brevity_penalty": 1.0, "length_ratio": 3.1914893617021276, "translation_length": 150, "reference_length": 47}
{"bleu": 0.0, "precisions": [0.06837606837606838, 0.008583690987124463, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.324324324324325, "translation_length": 234, "reference_length": 37}
{"bleu": 0.0, "precisions": [0.018867924528301886, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.4193548387096775, "translation_length": 106, "reference_length": 31}
{"bleu": 0.5462558603676451, "precisions": [0.6816816816816816, 0.6385542168674698, 0.6374622356495468, 0.6363636363636364], "brevity_penalty": 0.8426773190622507, "length_ratio": 0.8538461538461538, "translation_length": 333, "reference_length": 390}
{"bleu": 0.08815762218464625, "precisions": [0.27705627705627706, 0.07391304347826087, 0.0611353711790393, 0.04824561403508772], "brevity_penalty": 1.0, "length_ratio": 1.5298013245033113, "translation_length": 231, "reference_length": 151}
{"bleu": 0.0, "precisions": [0.005050505050505051, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 28.285714285714285, "translation_length": 198, "reference_length": 7}
{"bleu": 0.0, "precisions": [0.10526315789473684, 0.0, 0.0, 0.0], "brevity_penalty": 0.47862297251123215, "length_ratio": 0.5757575757575758, "translation_length": 76, "reference_length": 132}
{"error": "CUDA out of memory. Tried to allocate 188.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 98.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Process 774124 has 154.00 MiB memory in use. Including non-PyTorch memory, this process has 9.90 GiB memory in use. Of the allocated memory 9.61 GiB is allocated by PyTorch, and 87.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 18.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Process 774124 has 154.00 MiB memory in use. Including non-PyTorch memory, this process has 9.98 GiB memory in use. Of the allocated memory 9.65 GiB is allocated by PyTorch, and 133.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.01579100962039888, "precisions": [0.07, 0.017543859649122806, 0.010050251256281407, 0.005037783375314861], "brevity_penalty": 1.0, "length_ratio": 4.301075268817204, "translation_length": 400, "reference_length": 93}
{"bleu": 0.05504516129976681, "precisions": [0.08397790055248619, 0.05309734513274336, 0.047619047619047616, 0.043237250554323724], "brevity_penalty": 1.0, "length_ratio": 5.727848101265823, "translation_length": 905, "reference_length": 158}
{"bleu": 0.7792156419100181, "precisions": [0.8289601554907677, 0.7772373540856031, 0.7614410905550146, 0.7514619883040936], "brevity_penalty": 1.0, "length_ratio": 1.1017130620985012, "translation_length": 1029, "reference_length": 934}
{"bleu": 0.6739038433694766, "precisions": [0.8558951965065502, 0.8377192982456141, 0.8325991189427313, 0.827433628318584], "brevity_penalty": 0.8038515940517704, "length_ratio": 0.8207885304659498, "translation_length": 229, "reference_length": 279}
{"bleu": 0.0, "precisions": [0.11940298507462686, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.4565217391304348, "translation_length": 67, "reference_length": 46}
{"bleu": 0.052129740778158726, "precisions": [0.05360824742268041, 0.05263157894736842, 0.05165289256198347, 0.050672182006204755], "brevity_penalty": 1.0, "length_ratio": 16.440677966101696, "translation_length": 970, "reference_length": 59}
{"bleu": 4.1697242910818813e-08, "precisions": [0.5, 0.2868217054263566, 0.2578125, 0.23622047244094488], "brevity_penalty": 1.363975153390535e-07, "length_ratio": 0.059496567505720827, "translation_length": 130, "reference_length": 2185}
{"bleu": 0.0, "precisions": [0.0018867924528301887, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 48.18181818181818, "translation_length": 1060, "reference_length": 22}
{"bleu": 0.0, "precisions": [0.20833333333333334, 0.0, 0.0, 0.0], "brevity_penalty": 4.521115693830031e-05, "length_ratio": 0.09087466868610375, "translation_length": 240, "reference_length": 2641}
{"bleu": 0.12033276507791198, "precisions": [0.2240085744908896, 0.1072961373390558, 0.09774436090225563, 0.08924731182795699], "brevity_penalty": 1.0, "length_ratio": 2.7441176470588236, "translation_length": 933, "reference_length": 340}
{"bleu": 0.0, "precisions": [0.026016260162601626, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.4698795180722892, "translation_length": 615, "reference_length": 249}
{"bleu": 0.0295208850678552, "precisions": [0.030619865571321882, 0.029895366218236172, 0.02916978309648467, 0.02844311377245509], "brevity_penalty": 1.0, "length_ratio": 27.895833333333332, "translation_length": 1339, "reference_length": 48}
{"bleu": 0.0, "precisions": [0.07120085015940489, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 5.114130434782608, "translation_length": 941, "reference_length": 184}
{"bleu": 0.06207844817488437, "precisions": [0.47629310344827586, 0.15334773218142547, 0.11471861471861472, 0.0911062906724512], "brevity_penalty": 0.3734714213611366, "length_ratio": 0.503800217155266, "translation_length": 464, "reference_length": 921}
{"bleu": 0.08013169241314806, "precisions": [0.08151093439363817, 0.08059701492537313, 0.0796812749003984, 0.07876370887337986], "brevity_penalty": 1.0, "length_ratio": 11.303370786516854, "translation_length": 1006, "reference_length": 89}
{"bleu": 1.731973800353728e-07, "precisions": [0.4046306504961411, 0.31236203090507725, 0.3027624309392265, 0.29867256637168144], "brevity_penalty": 5.297094673800643e-07, "length_ratio": 0.06472099329242187, "translation_length": 907, "reference_length": 14014}
{"bleu": 0.018090687987756118, "precisions": [0.021436227224008574, 0.019313304721030045, 0.017185821697099892, 0.015053763440860216], "brevity_penalty": 1.0, "length_ratio": 44.42857142857143, "translation_length": 933, "reference_length": 21}
{"bleu": 3.7449505402157053e-19, "precisions": [0.23529411764705882, 0.05952380952380952, 0.04819277108433735, 0.036585365853658534], "brevity_penalty": 5.3124923043552385e-18, "length_ratio": 0.02452394691286786, "translation_length": 85, "reference_length": 3466}
{"bleu": 0.09463969278258813, "precisions": [0.10253699788583509, 0.09417989417989418, 0.09216101694915255, 0.09013785790031813], "brevity_penalty": 1.0, "length_ratio": 5.086021505376344, "translation_length": 946, "reference_length": 186}
{"bleu": 0.20455542584486977, "precisions": [0.20759493670886076, 0.20558375634517767, 0.2035623409669211, 0.20153061224489796], "brevity_penalty": 1.0, "length_ratio": 4.438202247191011, "translation_length": 395, "reference_length": 89}
{"bleu": 0.0, "precisions": [0.003076923076923077, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 46.42857142857143, "translation_length": 975, "reference_length": 21}
{"bleu": 0.00771729091109587, "precisions": [0.6542261251372119, 0.5285714285714286, 0.5115511551155115, 0.5], "brevity_penalty": 0.01415116554525107, "length_ratio": 0.19018789144050105, "translation_length": 911, "reference_length": 4790}
{"bleu": 0.0, "precisions": [0.02, 0.013422818791946308, 0.006756756756756757, 0.0], "brevity_penalty": 1.0, "length_ratio": 11.538461538461538, "translation_length": 150, "reference_length": 13}
{"bleu": 0.0, "precisions": [0.16149068322981366, 0.012461059190031152, 0.0, 0.0], "brevity_penalty": 0.9397778125906119, "length_ratio": 0.9415204678362573, "translation_length": 322, "reference_length": 342}
{"bleu": 0.0, "precisions": [0.036231884057971016, 0.0, 0.0, 0.0], "brevity_penalty": 0.1368143427285411, "length_ratio": 0.33454545454545453, "translation_length": 276, "reference_length": 825}
{"bleu": 0.019946458976151306, "precisions": [0.14457831325301204, 0.02613065326633166, 0.015090543259557344, 0.007049345417925478], "brevity_penalty": 0.7922076581446512, "length_ratio": 0.8110749185667753, "translation_length": 996, "reference_length": 1228}
{"bleu": 0.0, "precisions": [0.02433862433862434, 0.006355932203389831, 0.003181336161187699, 0.0], "brevity_penalty": 1.0, "length_ratio": 21.0, "translation_length": 945, "reference_length": 45}
{"bleu": 0.010860356014380979, "precisions": [0.03614457831325301, 0.009045226130653266, 0.007042253521126761, 0.006042296072507553], "brevity_penalty": 1.0, "length_ratio": 9.054545454545455, "translation_length": 996, "reference_length": 110}
{"bleu": 0.030126174286175266, "precisions": [0.09536784741144415, 0.0273224043715847, 0.019178082191780823, 0.016483516483516484], "brevity_penalty": 1.0, "length_ratio": 3.3981481481481484, "translation_length": 367, "reference_length": 108}
{"bleu": 0.009924437983514759, "precisions": [0.06063432835820896, 0.013071895424836602, 0.0065420560747663555, 0.0018709073900841909], "brevity_penalty": 1.0, "length_ratio": 8.64516129032258, "translation_length": 1072, "reference_length": 124}
{"bleu": 0.0, "precisions": [0.177734375, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.199063231850117, "translation_length": 512, "reference_length": 427}
{"bleu": 0.0, "precisions": [0.21153846153846154, 0.0, 0.0, 0.0], "brevity_penalty": 3.7990131179299698e-06, "length_ratio": 0.07417974322396577, "translation_length": 52, "reference_length": 701}
{"error": "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 210.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Including non-PyTorch memory, this process has 9.95 GiB memory in use. Of the allocated memory 9.47 GiB is allocated by PyTorch, and 270.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.11804008908685969, 0.011160714285714286, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.5354330708661417, "translation_length": 449, "reference_length": 127}
{"bleu": 0.12754786478748636, "precisions": [0.4863013698630137, 0.296551724137931, 0.2638888888888889, 0.2517482517482518], "brevity_penalty": 0.40768507648978786, "length_ratio": 0.5270758122743683, "translation_length": 146, "reference_length": 277}
{"bleu": 0.025850333144530238, "precisions": [0.06526104417670683, 0.02814070351758794, 0.01609657947686117, 0.015105740181268883], "brevity_penalty": 1.0, "length_ratio": 9.485714285714286, "translation_length": 996, "reference_length": 105}
{"bleu": 0.07690470436901327, "precisions": [0.09766454352441614, 0.07863974495217853, 0.07127659574468086, 0.06389776357827476], "brevity_penalty": 1.0, "length_ratio": 7.785123966942149, "translation_length": 942, "reference_length": 121}
{"bleu": 0.12618708199975753, "precisions": [0.1366906474820144, 0.13357400722021662, 0.12318840579710146, 0.11272727272727273], "brevity_penalty": 1.0, "length_ratio": 6.177777777777778, "translation_length": 278, "reference_length": 45}
{"bleu": 0.20663330583061953, "precisions": [0.27289048473967686, 0.2014388489208633, 0.18558558558558558, 0.17870036101083034], "brevity_penalty": 1.0, "length_ratio": 1.2545045045045045, "translation_length": 557, "reference_length": 444}
{"error": "CUDA out of memory. Tried to allocate 218.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 92.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Including non-PyTorch memory, this process has 10.06 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 324.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 52.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Including non-PyTorch memory, this process has 10.10 GiB memory in use. Of the allocated memory 9.62 GiB is allocated by PyTorch, and 283.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.043010752688172046, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.5897435897435896, "translation_length": 186, "reference_length": 117}
{"bleu": 0.1092965029988022, "precisions": [0.979381443298969, 0.9716129032258064, 0.9715762273901809, 0.9715394566623544], "brevity_penalty": 0.1122692056261365, "length_ratio": 0.31378892033966843, "translation_length": 776, "reference_length": 2473}
{"bleu": 0.0, "precisions": [0.10948905109489052, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.186046511627907, "translation_length": 137, "reference_length": 43}
{"bleu": 0.1278631951832379, "precisions": [0.1329987452948557, 0.12814070351758794, 0.12578616352201258, 0.12468513853904283], "brevity_penalty": 1.0, "length_ratio": 7.3119266055045875, "translation_length": 797, "reference_length": 109}
{"bleu": 6.707300693081872e-14, "precisions": [0.6897435897435897, 0.46272493573264784, 0.4329896907216495, 0.4186046511627907], "brevity_penalty": 1.3676492476522503e-13, "length_ratio": 0.03265784625690839, "translation_length": 390, "reference_length": 11942}
{"bleu": 0.05085479207384941, "precisions": [0.21311475409836064, 0.06611570247933884, 0.041666666666666664, 0.03361344537815126], "brevity_penalty": 0.7630041541029989, "length_ratio": 0.7870967741935484, "translation_length": 122, "reference_length": 155}
{"bleu": 0.074717385923977, "precisions": [0.11071428571428571, 0.08602150537634409, 0.06474820143884892, 0.05054151624548736], "brevity_penalty": 1.0, "length_ratio": 4.912280701754386, "translation_length": 280, "reference_length": 57}
{"bleu": 0.09209009868536391, "precisions": [0.09357997823721437, 0.09259259259259259, 0.0916030534351145, 0.0906113537117904], "brevity_penalty": 1.0, "length_ratio": 9.881720430107526, "translation_length": 919, "reference_length": 93}
{"bleu": 0.24005833291531167, "precisions": [0.6477419354838709, 0.5658914728682171, 0.5575679172056921, 0.5518134715025906], "brevity_penalty": 0.4142480530688542, "length_ratio": 0.5315500685871056, "translation_length": 775, "reference_length": 1458}
{"bleu": 6.650862359064338e-05, "precisions": [0.36742424242424243, 0.11406844106463879, 0.08778625954198473, 0.06513409961685823], "brevity_penalty": 0.0005345469944550267, "length_ratio": 0.11717709720372836, "translation_length": 264, "reference_length": 2253}
{"bleu": 0.0, "precisions": [0.4310850439882698, 0.13823529411764707, 0.058997050147492625, 0.0], "brevity_penalty": 0.11860403045635684, "length_ratio": 0.3192883895131086, "translation_length": 341, "reference_length": 1068}
{"bleu": 0.000593163975831203, "precisions": [0.19622245540398742, 0.03466386554621849, 0.025236593059936908, 0.022105263157894735], "brevity_penalty": 0.01343961226969412, "length_ratio": 0.1883399209486166, "translation_length": 953, "reference_length": 5060}
{"bleu": 6.68709535421131e-05, "precisions": [0.41822620016273393, 0.22068403908794787, 0.1687041564792176, 0.1166394779771615], "brevity_penalty": 0.0003239284839921792, "length_ratio": 0.11068083573487032, "translation_length": 1229, "reference_length": 11104}
{"bleu": 0.0, "precisions": [0.014285714285714285, 0.0040858018386108275, 0.002044989775051125, 0.0], "brevity_penalty": 1.0, "length_ratio": 23.902439024390244, "translation_length": 980, "reference_length": 41}
{"bleu": 0.0, "precisions": [0.015748031496062992, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 18.142857142857142, "translation_length": 762, "reference_length": 42}
{"bleu": 0.053105282218365205, "precisions": [0.12835820895522387, 0.04790419161676647, 0.03903903903903904, 0.03313253012048193], "brevity_penalty": 1.0, "length_ratio": 2.427536231884058, "translation_length": 335, "reference_length": 138}
{"bleu": 1.2371774743681098e-68, "precisions": [0.6190476190476191, 0.43548387096774194, 0.4262295081967213, 0.4166666666666667], "brevity_penalty": 2.6448430374240827e-68, "length_ratio": 0.00638556659233732, "translation_length": 63, "reference_length": 9866}
{"bleu": 0.2310221160328582, "precisions": [0.7833333333333333, 0.7128547579298832, 0.6939799331103679, 0.6750418760469011], "brevity_penalty": 0.32303325642225295, "length_ratio": 0.4694835680751174, "translation_length": 600, "reference_length": 1278}
{"error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 186.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Including non-PyTorch memory, this process has 9.97 GiB memory in use. Of the allocated memory 9.33 GiB is allocated by PyTorch, and 439.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.4806201550387597, 0.0, 0.0, 0.0], "brevity_penalty": 1.2069814875405884e-08, "length_ratio": 0.05199516324062878, "translation_length": 129, "reference_length": 2481}
{"error": "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 248.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Including non-PyTorch memory, this process has 9.91 GiB memory in use. Of the allocated memory 9.39 GiB is allocated by PyTorch, and 319.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 28.69 MiB is free. Process 1117566 has 606.00 MiB memory in use. Including non-PyTorch memory, this process has 10.12 GiB memory in use. Of the allocated memory 9.55 GiB is allocated by PyTorch, and 371.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.11311803984428015, "precisions": [0.14168377823408623, 0.11316872427983539, 0.10515463917525773, 0.09710743801652892], "brevity_penalty": 1.0, "length_ratio": 5.47191011235955, "translation_length": 487, "reference_length": 89}
{"bleu": 0.09340696065682406, "precisions": [0.12614445574771108, 0.08961303462321792, 0.08460754332313965, 0.07959183673469387], "brevity_penalty": 1.0, "length_ratio": 6.182389937106918, "translation_length": 983, "reference_length": 159}
{"bleu": 0.06560603887112117, "precisions": [0.16293929712460065, 0.060897435897435896, 0.04823151125401929, 0.03870967741935484], "brevity_penalty": 1.0, "length_ratio": 1.95625, "translation_length": 313, "reference_length": 160}
{"bleu": 0.027717652873065712, "precisions": [0.15742574257425743, 0.019821605550049554, 0.015873015873015872, 0.011916583912611719], "brevity_penalty": 1.0, "length_ratio": 2.0159680638722555, "translation_length": 1010, "reference_length": 501}
{"bleu": 0.0, "precisions": [0.00625, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.620938628158845, "translation_length": 1280, "reference_length": 277}
{"bleu": 0.0, "precisions": [0.015444015444015444, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 14.38888888888889, "translation_length": 259, "reference_length": 18}
{"bleu": 0.03359171325304442, "precisions": [0.03501945525291829, 0.034079844206426485, 0.03313840155945419, 0.03219512195121951], "brevity_penalty": 1.0, "length_ratio": 23.906976744186046, "translation_length": 1028, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.025, 0.008368200836820083, 0.004201680672268907, 0.0], "brevity_penalty": 1.0, "length_ratio": 13.333333333333334, "translation_length": 240, "reference_length": 18}
{"bleu": 0.3135650979551922, "precisions": [0.8184818481848185, 0.7847682119205298, 0.7774086378737541, 0.77], "brevity_penalty": 0.39820350741843563, "length_ratio": 0.520618556701031, "translation_length": 303, "reference_length": 582}
{"bleu": 0.000602278404801932, "precisions": [0.35689851767388825, 0.15182648401826485, 0.013714285714285714, 0.006864988558352402], "brevity_penalty": 0.01267275296326486, "length_ratio": 0.1862786745964316, "translation_length": 877, "reference_length": 4708}
{"bleu": 0.018252305219082617, "precisions": [0.02142857142857143, 0.01940755873340143, 0.017382413087934562, 0.015353121801432957], "brevity_penalty": 1.0, "length_ratio": 33.793103448275865, "translation_length": 980, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.014736842105263158, 0.002107481559536354, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 32.758620689655174, "translation_length": 950, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.2857142857142857, 0.04838709677419355, 0.01639344262295082, 0.0], "brevity_penalty": 0.005934431002839445, "length_ratio": 0.16321243523316062, "translation_length": 63, "reference_length": 386}
{"bleu": 0.0, "precisions": [0.03680336487907466, 0.01263157894736842, 0.006322444678609062, 0.0], "brevity_penalty": 1.0, "length_ratio": 12.68, "translation_length": 951, "reference_length": 75}
{"bleu": 0.0, "precisions": [0.005917159763313609, 0.0019743336623889436, 0.0009881422924901185, 0.0], "brevity_penalty": 1.0, "length_ratio": 59.64705882352941, "translation_length": 1014, "reference_length": 17}
{"bleu": 0.0, "precisions": [0.08823529411764706, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.096774193548387, "translation_length": 68, "reference_length": 62}
{"bleu": 0.0, "precisions": [0.08527131782945736, 0.0078125, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.5925925925925926, "translation_length": 129, "reference_length": 81}
{"bleu": 0.0, "precisions": [0.06666666666666667, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.1951219512195124, "translation_length": 90, "reference_length": 41}
{"bleu": 0.12446603279124052, "precisions": [0.5725190839694656, 0.36923076923076925, 0.3333333333333333, 0.3125], "brevity_penalty": 0.32310724197518115, "length_ratio": 0.46953405017921146, "translation_length": 131, "reference_length": 279}
{"bleu": 0.0, "precisions": [0.03297872340425532, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 5.949367088607595, "translation_length": 940, "reference_length": 158}
{"bleu": 0.04536080763510752, "precisions": [0.05361930294906166, 0.04838709677419355, 0.0431266846361186, 0.03783783783783784], "brevity_penalty": 1.0, "length_ratio": 17.761904761904763, "translation_length": 373, "reference_length": 21}
{"bleu": 0.06402462834683882, "precisions": [0.06779661016949153, 0.06361323155216285, 0.06281833616298811, 0.062022090059473234], "brevity_penalty": 1.0, "length_ratio": 14.216867469879517, "translation_length": 1180, "reference_length": 83}
{"bleu": 2.2892942954130576e-13, "precisions": [0.5172413793103449, 0.2807017543859649, 0.23214285714285715, 0.14545454545454545], "brevity_penalty": 8.651598832207672e-13, "length_ratio": 0.0347513481126423, "translation_length": 58, "reference_length": 1669}
{"bleu": 1.3788100181575288e-34, "precisions": [0.4883720930232558, 0.15625, 0.11811023622047244, 0.09523809523809523], "brevity_penalty": 8.055400807211714e-34, "length_ratio": 0.01295310774174114, "translation_length": 129, "reference_length": 9959}
{"bleu": 0.024100896613018927, "precisions": [0.28361581920903955, 0.014705882352941176, 0.010192525481313703, 0.007936507936507936], "brevity_penalty": 1.0, "length_ratio": 1.1629434954007885, "translation_length": 885, "reference_length": 761}
{"error": "CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 196.69 MiB is free. Including non-PyTorch memory, this process has 10.55 GiB memory in use. Of the allocated memory 10.06 GiB is allocated by PyTorch, and 294.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.028350491335947334, "precisions": [0.02982107355864811, 0.028855721393034824, 0.027888446215139442, 0.026919242273180457], "brevity_penalty": 1.0, "length_ratio": 27.18918918918919, "translation_length": 1006, "reference_length": 37}
{"bleu": 0.02033739156538269, "precisions": [0.028484231943031537, 0.021384928716904276, 0.01834862385321101, 0.015306122448979591], "brevity_penalty": 1.0, "length_ratio": 31.70967741935484, "translation_length": 983, "reference_length": 31}
{"bleu": 9.214629371701072e-06, "precisions": [0.9409547738693468, 0.9270440251572327, 0.9269521410579346, 0.926860025220681], "brevity_penalty": 9.903591732806372e-06, "length_ratio": 0.07985553772070626, "translation_length": 796, "reference_length": 9968}
{"bleu": 0.0, "precisions": [0.0061162079510703364, 0.0020408163265306124, 0.0010214504596527069, 0.0], "brevity_penalty": 1.0, "length_ratio": 54.5, "translation_length": 981, "reference_length": 18}
{"bleu": 0.020210533053470203, "precisions": [0.06578947368421052, 0.017223910840932118, 0.013184584178498986, 0.01116751269035533], "brevity_penalty": 1.0, "length_ratio": 6.415584415584416, "translation_length": 988, "reference_length": 154}
{"bleu": 0.04519024450344928, "precisions": [0.5125, 0.4050632911392405, 0.3974358974358974, 0.38961038961038963], "brevity_penalty": 0.10672498360043615, "length_ratio": 0.3088803088803089, "translation_length": 80, "reference_length": 259}
{"bleu": 0.051024487200436425, "precisions": [0.37254901960784315, 0.2204724409448819, 0.16205533596837945, 0.10714285714285714], "brevity_penalty": 0.2625654480923914, "length_ratio": 0.4278523489932886, "translation_length": 255, "reference_length": 596}
{"bleu": 0.05783696262572227, "precisions": [0.1111111111111111, 0.064, 0.04838709677419355, 0.032520325203252036], "brevity_penalty": 1.0, "length_ratio": 3.073170731707317, "translation_length": 126, "reference_length": 41}
{"bleu": 0.6232299142379445, "precisions": [0.8173913043478261, 0.7894736842105263, 0.7787610619469026, 0.7678571428571429], "brevity_penalty": 0.7907427315390552, "length_ratio": 0.8098591549295775, "translation_length": 115, "reference_length": 142}
{"error": "CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 140.69 MiB is free. Including non-PyTorch memory, this process has 10.61 GiB memory in use. Of the allocated memory 10.09 GiB is allocated by PyTorch, and 312.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.011764705882352941, 0.0029455081001472753, 0.0014749262536873156, 0.0], "brevity_penalty": 1.0, "length_ratio": 37.77777777777778, "translation_length": 680, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.1348314606741573, 0.0, 0.0, 0.0], "brevity_penalty": 0.06483205926789484, "length_ratio": 0.26766917293233083, "translation_length": 178, "reference_length": 665}
{"bleu": 0.2131270228258432, "precisions": [0.30201342281879195, 0.20945945945945946, 0.19047619047619047, 0.17123287671232876], "brevity_penalty": 1.0, "length_ratio": 1.3925233644859814, "translation_length": 149, "reference_length": 107}
{"bleu": 4.831256821281992e-15, "precisions": [0.7052631578947368, 0.5212765957446809, 0.4946236559139785, 0.4673913043478261], "brevity_penalty": 8.947802521878685e-15, "length_ratio": 0.029987373737373736, "translation_length": 95, "reference_length": 3168}
{"bleu": 0.2860849205298861, "precisions": [0.3681528662420382, 0.2844387755102041, 0.26053639846743293, 0.24552429667519182], "brevity_penalty": 1.0, "length_ratio": 1.6020408163265305, "translation_length": 785, "reference_length": 490}
{"bleu": 0.24150929686924488, "precisions": [0.3607103218645949, 0.25, 0.20912124582869857, 0.18040089086859687], "brevity_penalty": 1.0, "length_ratio": 1.8692946058091287, "translation_length": 901, "reference_length": 482}
{"bleu": 0.04163096749850134, "precisions": [0.15920915712799166, 0.03333333333333333, 0.027111574556830033, 0.020876826722338204], "brevity_penalty": 1.0, "length_ratio": 1.318244170096022, "translation_length": 961, "reference_length": 729}
{"bleu": 0.0, "precisions": [0.09243697478991597, 0.004219409282700422, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.7246376811594204, "translation_length": 238, "reference_length": 138}
{"bleu": 0.08324526000289541, "precisions": [0.1076581576026637, 0.08555555555555555, 0.07675194660734148, 0.06792873051224944], "brevity_penalty": 1.0, "length_ratio": 5.738853503184713, "translation_length": 901, "reference_length": 157}
{"bleu": 0.0, "precisions": [0.005172413793103448, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 20.350877192982455, "translation_length": 1160, "reference_length": 57}
{"bleu": 0.024493514074007714, "precisions": [0.05637982195845697, 0.023809523809523808, 0.01791044776119403, 0.014970059880239521], "brevity_penalty": 1.0, "length_ratio": 9.911764705882353, "translation_length": 337, "reference_length": 34}
{"bleu": 0.7023613859782101, "precisions": [0.9954001839926403, 0.9935543278084714, 0.9907834101382489, 0.9907749077490775], "brevity_penalty": 0.7075788805376857, "length_ratio": 0.7429938482570062, "translation_length": 1087, "reference_length": 1463}
{"bleu": 5.283078537986422e-07, "precisions": [0.476, 0.30120481927710846, 0.2903225806451613, 0.2793522267206478], "brevity_penalty": 1.6088353915567235e-06, "length_ratio": 0.0697350069735007, "translation_length": 250, "reference_length": 3585}
{"bleu": 0.0, "precisions": [0.33653846153846156, 0.04854368932038835, 0.0196078431372549, 0.0], "brevity_penalty": 8.672717043841027e-27, "length_ratio": 0.016390858944050433, "translation_length": 104, "reference_length": 6345}
{"bleu": 0.06490102064861127, "precisions": [0.256353591160221, 0.05752212389380531, 0.03875968992248062, 0.031042128603104215], "brevity_penalty": 1.0, "length_ratio": 1.3923076923076922, "translation_length": 905, "reference_length": 650}
{"bleu": 0.0, "precisions": [0.2879581151832461, 0.031578947368421054, 0.0, 0.0], "brevity_penalty": 0.31440665139095303, "length_ratio": 0.46359223300970875, "translation_length": 191, "reference_length": 412}
{"bleu": 0.11428864539536833, "precisions": [0.9774436090225563, 0.9560853199498118, 0.9434673366834171, 0.9333333333333333], "brevity_penalty": 0.11999553420154639, "length_ratio": 0.3204819277108434, "translation_length": 798, "reference_length": 2490}
{"bleu": 0.030089516795522818, "precisions": [0.03474320241691843, 0.03177004538577912, 0.02878787878787879, 0.025796661608497723], "brevity_penalty": 1.0, "length_ratio": 22.066666666666666, "translation_length": 662, "reference_length": 30}
{"bleu": 0.0008472407344260575, "precisions": [0.9953917050691244, 0.9907727797001153, 0.9884526558891455, 0.9849710982658959], "brevity_penalty": 0.0008558939708709159, "length_ratio": 0.12401771681668809, "translation_length": 868, "reference_length": 6999}
{"error": "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 116.69 MiB is free. Including non-PyTorch memory, this process has 10.63 GiB memory in use. Of the allocated memory 9.89 GiB is allocated by PyTorch, and 541.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 16.69 MiB is free. Including non-PyTorch memory, this process has 10.73 GiB memory in use. Of the allocated memory 9.99 GiB is allocated by PyTorch, and 539.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.21875, 0.010471204188481676, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.1428571428571428, "translation_length": 192, "reference_length": 168}
{"bleu": 0.0, "precisions": [0.1619718309859155, 0.0070921985815602835, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.5604395604395604, "translation_length": 142, "reference_length": 91}
{"bleu": 0.0, "precisions": [0.19540229885057472, 0.046242774566473986, 0.023255813953488372, 0.0], "brevity_penalty": 0.021267510218410016, "length_ratio": 0.20616113744075829, "translation_length": 174, "reference_length": 844}
{"bleu": 0.0, "precisions": [0.03902439024390244, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.3076923076923075, "translation_length": 410, "reference_length": 65}
{"bleu": 0.0, "precisions": [0.007223942208462332, 0.0010330578512396695, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 40.375, "translation_length": 969, "reference_length": 24}
{"bleu": 0.0, "precisions": [0.04639175257731959, 0.0051813471502590676, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.041666666666667, "translation_length": 194, "reference_length": 48}
{"bleu": 0.0, "precisions": [0.11764705882352941, 0.0, 0.0, 0.0], "brevity_penalty": 4.6963952610398475e-09, "length_ratio": 0.04956268221574344, "translation_length": 17, "reference_length": 343}
{"bleu": 0.0, "precisions": [0.16837782340862423, 0.011305241521068859, 0.0051440329218107, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.0668127053669223, "translation_length": 974, "reference_length": 913}
{"bleu": 1.445093580249698e-28, "precisions": [0.640625, 0.49206349206349204, 0.46774193548387094, 0.4426229508196721], "brevity_penalty": 2.8591020409407206e-28, "length_ratio": 0.015522677661896677, "translation_length": 64, "reference_length": 4123}
{"bleu": 0.03293577614922197, "precisions": [0.06502242152466367, 0.04044943820224719, 0.024774774774774775, 0.01805869074492099], "brevity_penalty": 1.0, "length_ratio": 9.911111111111111, "translation_length": 446, "reference_length": 45}
{"bleu": 0.12671265443459442, "precisions": [0.2242798353909465, 0.12461380020597322, 0.10515463917525773, 0.08771929824561403], "brevity_penalty": 1.0, "length_ratio": 2.370731707317073, "translation_length": 972, "reference_length": 410}
{"bleu": 0.24344802144722846, "precisions": [0.2465753424657534, 0.2445054945054945, 0.24242424242424243, 0.24033149171270718], "brevity_penalty": 1.0, "length_ratio": 3.7628865979381443, "translation_length": 365, "reference_length": 97}
{"bleu": 0.09849360547040086, "precisions": [0.53125, 0.19603753910323254, 0.15866388308977036, 0.12748171368861025], "brevity_penalty": 0.45974498055247137, "length_ratio": 0.5627198124267292, "translation_length": 960, "reference_length": 1706}
{"bleu": 1.2370286295338279e-05, "precisions": [0.6503623188405797, 0.41197822141560797, 0.32, 0.2641165755919854], "brevity_penalty": 3.1888635372453635e-05, "length_ratio": 0.0880804212541886, "translation_length": 552, "reference_length": 6267}
{"bleu": 0.07001980770478816, "precisions": [0.21701199563794984, 0.12554585152838427, 0.12131147540983607, 0.11706783369803063], "brevity_penalty": 0.4992459152214051, "length_ratio": 0.5900900900900901, "translation_length": 917, "reference_length": 1554}
{"bleu": 0.0, "precisions": [0.04851157662624035, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.572463768115942, "translation_length": 907, "reference_length": 138}
{"bleu": 0.0, "precisions": [0.12645161290322582, 0.00516795865633075, 0.00258732212160414, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.491961414790997, "translation_length": 775, "reference_length": 311}
{"bleu": 1.8175189706400384e-08, "precisions": [0.13211600429645542, 0.007526881720430108, 0.0032292787944025836, 0.0010775862068965517], "brevity_penalty": 2.369719438195526e-06, "length_ratio": 0.07167051578137028, "translation_length": 931, "reference_length": 12990}
{"bleu": 0.0, "precisions": [0.07766990291262135, 0.00980392156862745, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.019607843137255, "translation_length": 103, "reference_length": 51}
{"bleu": 0.00765350790293419, "precisions": [0.010428736964078795, 0.008120649651972157, 0.006968641114982578, 0.005813953488372093], "brevity_penalty": 1.0, "length_ratio": 41.095238095238095, "translation_length": 863, "reference_length": 21}
{"bleu": 0.0, "precisions": [0.22340425531914893, 0.0, 0.0, 0.0], "brevity_penalty": 1.3023769012501397e-38, "length_ratio": 0.011333494092114782, "translation_length": 94, "reference_length": 8294}
{"error": "CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 118.69 MiB is free. Including non-PyTorch memory, this process has 10.63 GiB memory in use. Of the allocated memory 9.94 GiB is allocated by PyTorch, and 495.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.012108530429949594, "precisions": [0.025, 0.01251303441084463, 0.009394572025052192, 0.0073145245559038665], "brevity_penalty": 1.0, "length_ratio": 16.271186440677965, "translation_length": 960, "reference_length": 59}
{"bleu": 2.2434029063604256e-26, "precisions": [0.5546875, 0.31496062992125984, 0.2857142857142857, 0.272], "brevity_penalty": 6.572126299741921e-26, "length_ratio": 0.01695364238410596, "translation_length": 128, "reference_length": 7550}
{"bleu": 0.3597538363857189, "precisions": [0.5336405529953917, 0.45940959409594095, 0.4293628808864266, 0.3955637707948244], "brevity_penalty": 0.7964031355977021, "length_ratio": 0.8145645645645646, "translation_length": 1085, "reference_length": 1332}
{"bleu": 0.00623144976581266, "precisions": [0.03825136612021858, 0.005470459518599562, 0.0032858707557502738, 0.0021929824561403508], "brevity_penalty": 1.0, "length_ratio": 7.56198347107438, "translation_length": 915, "reference_length": 121}
{"bleu": 7.701196564096848e-05, "precisions": [0.4952581664910432, 0.3048523206751055, 0.27983104540654696, 0.27906976744186046], "brevity_penalty": 0.00023370916798753702, "length_ratio": 0.10682125168842864, "translation_length": 949, "reference_length": 8884}
{"bleu": 0.11550159617418193, "precisions": [0.22778345250255363, 0.09406952965235174, 0.09211873080859775, 0.09016393442622951], "brevity_penalty": 1.0, "length_ratio": 1.7327433628318585, "translation_length": 979, "reference_length": 565}
{"bleu": 0.37563555880944566, "precisions": [0.3766968325791855, 0.37599093997734995, 0.37528344671201813, 0.3745743473325766], "brevity_penalty": 1.0, "length_ratio": 2.6, "translation_length": 884, "reference_length": 340}
{"bleu": 1.1653887874028365e-17, "precisions": [0.7972027972027972, 0.7605633802816901, 0.7588652482269503, 0.7571428571428571], "brevity_penalty": 1.5169076983030537e-17, "length_ratio": 0.02517162471395881, "translation_length": 143, "reference_length": 5681}
{"bleu": 0.0, "precisions": [0.03571428571428571, 0.0, 0.0, 0.0], "brevity_penalty": 0.9823013510997375, "length_ratio": 0.9824561403508771, "translation_length": 56, "reference_length": 57}
{"bleu": 0.6079804224371731, "precisions": [0.76010101010101, 0.6936708860759494, 0.649746192893401, 0.6157760814249363], "brevity_penalty": 0.8971018676125706, "length_ratio": 0.9020501138952164, "translation_length": 396, "reference_length": 439}
{"bleu": 0.08338276213197018, "precisions": [0.2644628099173554, 0.09166666666666666, 0.058823529411764705, 0.03389830508474576], "brevity_penalty": 1.0, "length_ratio": 1.0521739130434782, "translation_length": 121, "reference_length": 115}
{"bleu": 0.02707528024770272, "precisions": [0.125, 0.032388663967611336, 0.016260162601626018, 0.00816326530612245], "brevity_penalty": 1.0, "length_ratio": 4.0, "translation_length": 248, "reference_length": 62}
{"bleu": 0.08391040042355637, "precisions": [0.17519685039370078, 0.07684729064039408, 0.06903353057199212, 0.0631786771964462], "brevity_penalty": 0.9585602741490169, "length_ratio": 0.959395656279509, "translation_length": 1016, "reference_length": 1059}
{"bleu": 0.0, "precisions": [0.10576015108593012, 0.0, 0.0, 0.0], "brevity_penalty": 0.558430494776379, "length_ratio": 0.6318615751789977, "translation_length": 1059, "reference_length": 1676}
{"bleu": 0.004911476467352551, "precisions": [0.481941309255079, 0.25084745762711863, 0.20361990950226244, 0.16761041902604756], "brevity_penalty": 0.019378974458803017, "length_ratio": 0.20228310502283106, "translation_length": 886, "reference_length": 4380}
{"bleu": 0.44294558556233926, "precisions": [0.9234449760765551, 0.9016786570743405, 0.8942307692307693, 0.8867469879518072], "brevity_penalty": 0.4913855054398576, "length_ratio": 0.5846153846153846, "translation_length": 418, "reference_length": 715}
{"bleu": 6.857669826281316e-08, "precisions": [0.5701754385964912, 0.4336283185840708, 0.42857142857142855, 0.42342342342342343], "brevity_penalty": 1.4900317155640455e-07, "length_ratio": 0.05981112277019937, "translation_length": 114, "reference_length": 1906}
{"bleu": 0.3528599487315663, "precisions": [0.42963752665245203, 0.35965848452508004, 0.327991452991453, 0.3058823529411765], "brevity_penalty": 1.0, "length_ratio": 1.9623430962343096, "translation_length": 938, "reference_length": 478}
{"bleu": 0.16028178405668644, "precisions": [0.6139380530973452, 0.39313399778516056, 0.38470066518847007, 0.3762486126526082], "brevity_penalty": 0.37073912264966713, "length_ratio": 0.5019433647973348, "translation_length": 904, "reference_length": 1801}
{"bleu": 0.0, "precisions": [0.17613636363636365, 0.0, 0.0, 0.0], "brevity_penalty": 0.15777411684443315, "length_ratio": 0.35129740518962077, "translation_length": 176, "reference_length": 501}
{"bleu": 0.009886249480683581, "precisions": [0.31, 0.17017017017017017, 0.15831663326653306, 0.1464393179538616], "brevity_penalty": 0.05286572873835034, "length_ratio": 0.25380710659898476, "translation_length": 1000, "reference_length": 3940}
{"bleu": 0.17471407732693492, "precisions": [0.18565400843881857, 0.17529039070749736, 0.17124735729386892, 0.1671957671957672], "brevity_penalty": 1.0, "length_ratio": 3.2354948805460753, "translation_length": 948, "reference_length": 293}
{"bleu": 0.044492003194804564, "precisions": [0.06481481481481481, 0.056074766355140186, 0.03773584905660377, 0.02857142857142857], "brevity_penalty": 1.0, "length_ratio": 15.428571428571429, "translation_length": 108, "reference_length": 7}
{"bleu": 0.10818943277614262, "precisions": [0.5108853410740203, 0.17005813953488372, 0.1586608442503639, 0.14868804664723032], "brevity_penalty": 0.5084733238207467, "length_ratio": 0.5965367965367966, "translation_length": 689, "reference_length": 1155}
{"bleu": 0.03526315115126715, "precisions": [0.04133858267716536, 0.03645320197044335, 0.03353057199211045, 0.03060217176702863], "brevity_penalty": 1.0, "length_ratio": 23.627906976744185, "translation_length": 1016, "reference_length": 43}
{"bleu": 0.04321409190691044, "precisions": [0.046460176991150445, 0.04434589800443459, 0.042222222222222223, 0.0400890868596882], "brevity_penalty": 1.0, "length_ratio": 16.142857142857142, "translation_length": 452, "reference_length": 28}
{"bleu": 0.06834271194032437, "precisions": [0.0783132530120482, 0.06934673366834171, 0.06539235412474849, 0.06143001007049345], "brevity_penalty": 1.0, "length_ratio": 12.0, "translation_length": 996, "reference_length": 83}
{"bleu": 0.008789768246383408, "precisions": [0.01346389228886169, 0.00980392156862745, 0.007361963190184049, 0.006142506142506142], "brevity_penalty": 1.0, "length_ratio": 38.904761904761905, "translation_length": 817, "reference_length": 21}
{"error": "CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 198.69 MiB is free. Including non-PyTorch memory, this process has 10.55 GiB memory in use. Of the allocated memory 10.02 GiB is allocated by PyTorch, and 326.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.02214022140221402, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 11.291666666666666, "translation_length": 271, "reference_length": 24}
{"error": "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 136.69 MiB is free. Including non-PyTorch memory, this process has 10.61 GiB memory in use. Of the allocated memory 9.96 GiB is allocated by PyTorch, and 453.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.061224489795918366, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.9696969696969697, "translation_length": 98, "reference_length": 33}
{"bleu": 0.04982856300360744, "precisions": [0.1625, 0.0759493670886076, 0.038461538461538464, 0.012987012987012988], "brevity_penalty": 1.0, "length_ratio": 1.4035087719298245, "translation_length": 80, "reference_length": 57}
{"bleu": 0.021941827541923205, "precisions": [0.09316770186335403, 0.03125, 0.012578616352201259, 0.006329113924050633], "brevity_penalty": 1.0, "length_ratio": 2.824561403508772, "translation_length": 161, "reference_length": 57}
{"bleu": 0.7151891489909705, "precisions": [0.7371349095966621, 0.7144846796657381, 0.7071129707112971, 0.702513966480447], "brevity_penalty": 1.0, "length_ratio": 1.274822695035461, "translation_length": 719, "reference_length": 564}
{"bleu": 9.553779701422803e-05, "precisions": [0.32628398791540786, 0.02620967741935484, 0.01917255297679112, 0.012121212121212121], "brevity_penalty": 0.002544511182888979, "length_ratio": 0.14339350180505414, "translation_length": 993, "reference_length": 6925}
{"bleu": 0.24719983617595281, "precisions": [0.3349705304518664, 0.22812192723697147, 0.2234251968503937, 0.2187192118226601], "brevity_penalty": 1.0, "length_ratio": 1.0059288537549407, "translation_length": 1018, "reference_length": 1012}
{"bleu": 0.0, "precisions": [0.059907834101382486, 0.0011534025374855825, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.382352941176471, "translation_length": 868, "reference_length": 136}
{"bleu": 0.6133693554689709, "precisions": [0.6308243727598566, 0.6151079136690647, 0.6064981949458483, 0.6014492753623188], "brevity_penalty": 1.0, "length_ratio": 1.4840425531914894, "translation_length": 279, "reference_length": 188}
{"bleu": 0.14393574417005825, "precisions": [0.5125260960334029, 0.367816091954023, 0.33158995815899583, 0.3068062827225131], "brevity_penalty": 0.3867813951882142, "length_ratio": 0.512847965738758, "translation_length": 958, "reference_length": 1868}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 150.0, "translation_length": 1050, "reference_length": 7}
{"bleu": 0.190758615875078, "precisions": [0.4105263157894737, 0.16415662650602408, 0.1478129713423831, 0.13293051359516617], "brevity_penalty": 1.0, "length_ratio": 1.2269372693726937, "translation_length": 665, "reference_length": 542}
{"bleu": 1.950478174951918e-06, "precisions": [0.6307692307692307, 0.34375, 0.31746031746031744, 0.2903225806451613], "brevity_penalty": 5.187644749748543e-06, "length_ratio": 0.07593457943925233, "translation_length": 65, "reference_length": 856}
{"bleu": 0.0, "precisions": [0.02850877192982456, 0.0043907793633369925, 0.002197802197802198, 0.0], "brevity_penalty": 1.0, "length_ratio": 16.285714285714285, "translation_length": 912, "reference_length": 56}
{"bleu": 0.004911513557987984, "precisions": [0.95, 0.9372384937238494, 0.9327731092436975, 0.9240506329113924], "brevity_penalty": 0.005247518399181385, "length_ratio": 0.16, "translation_length": 240, "reference_length": 1500}
{"bleu": 0.01956957980403829, "precisions": [0.45601851851851855, 0.30243337195828507, 0.28306264501160094, 0.2694541231126597], "brevity_penalty": 0.06110638674502714, "length_ratio": 0.26349496797804206, "translation_length": 864, "reference_length": 3279}
{"bleu": 0.00839518182185369, "precisions": [0.673469387755102, 0.5833333333333334, 0.574468085106383, 0.5652173913043478], "brevity_penalty": 0.014047566199406284, "length_ratio": 0.18992248062015504, "translation_length": 49, "reference_length": 258}
{"bleu": 0.04897352286232406, "precisions": [0.051457975986277875, 0.04982817869415808, 0.04819277108433735, 0.04655172413793104], "brevity_penalty": 1.0, "length_ratio": 15.756756756756756, "translation_length": 583, "reference_length": 37}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.333333333333333, "translation_length": 57, "reference_length": 9}
{"bleu": 0.0, "precisions": [0.11764705882352941, 0.0, 0.0, 0.0], "brevity_penalty": 2.8358372778421286e-05, "length_ratio": 0.08717948717948718, "translation_length": 17, "reference_length": 195}
{"bleu": 0.0, "precisions": [0.0076726342710997444, 0.0012804097311139564, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 35.54545454545455, "translation_length": 782, "reference_length": 22}
{"bleu": 0.020582678006071685, "precisions": [0.02208835341365462, 0.021105527638190954, 0.02012072434607646, 0.019133937562940583], "brevity_penalty": 1.0, "length_ratio": 34.3448275862069, "translation_length": 996, "reference_length": 29}
{"bleu": 0.00630842796415088, "precisions": [0.974477958236659, 0.9558652729384437, 0.9383720930232559, 0.9208381839348079], "brevity_penalty": 0.006660232213976452, "length_ratio": 0.16634504052489385, "translation_length": 862, "reference_length": 5182}
{"bleu": 0.19732468154588123, "precisions": [0.22580645161290322, 0.19705882352941176, 0.1887905604719764, 0.1804733727810651], "brevity_penalty": 1.0, "length_ratio": 3.3106796116504853, "translation_length": 341, "reference_length": 103}
{"bleu": 0.18016677236791984, "precisions": [0.20202020202020202, 0.17766497461928935, 0.17346938775510204, 0.16923076923076924], "brevity_penalty": 1.0, "length_ratio": 4.604651162790698, "translation_length": 198, "reference_length": 43}
{"bleu": 0.00740477586327462, "precisions": [0.8177777777777778, 0.6919642857142857, 0.6771300448430493, 0.6666666666666666], "brevity_penalty": 0.010415664079745424, "length_ratio": 0.17971246006389777, "translation_length": 225, "reference_length": 1252}
{"bleu": 0.0, "precisions": [0.010438413361169102, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.0031347962382444, "translation_length": 958, "reference_length": 319}
{"bleu": 0.01588531600414573, "precisions": [0.018005540166204988, 0.016643550624133148, 0.015277777777777777, 0.013908205841446454], "brevity_penalty": 1.0, "length_ratio": 34.38095238095238, "translation_length": 722, "reference_length": 21}
{"bleu": 0.0, "precisions": [0.054110301768990635, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.511737089201878, "translation_length": 961, "reference_length": 213}
{"bleu": 1.726368111074697e-15, "precisions": [0.46938775510204084, 0.2268041237113402, 0.21875, 0.21052631578947367], "brevity_penalty": 6.524152689675035e-15, "length_ratio": 0.029705971506517128, "translation_length": 98, "reference_length": 3299}
{"bleu": 0.03919040531801734, "precisions": [0.043933054393305436, 0.0387434554973822, 0.03773584905660377, 0.03672612801678909], "brevity_penalty": 1.0, "length_ratio": 21.244444444444444, "translation_length": 956, "reference_length": 45}
{"error": "CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 276.69 MiB is free. Including non-PyTorch memory, this process has 10.47 GiB memory in use. Of the allocated memory 9.94 GiB is allocated by PyTorch, and 328.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.009211873080859774, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 14.367647058823529, "translation_length": 977, "reference_length": 68}
{"bleu": 0.0, "precisions": [0.06728538283062645, 0.004645760743321719, 0.002325581395348837, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.78740157480315, "translation_length": 862, "reference_length": 127}
{"bleu": 0.05712606962192785, "precisions": [0.33486660533578655, 0.10957642725598526, 0.07649769585253456, 0.043357933579335796], "brevity_penalty": 0.5438859856065016, "length_ratio": 0.6214979988564894, "translation_length": 1087, "reference_length": 1749}
{"bleu": 0.2520780026803547, "precisions": [0.5885111371629543, 0.31338028169014087, 0.30434782608695654, 0.2964705882352941], "brevity_penalty": 0.7018437004683081, "length_ratio": 0.7385281385281385, "translation_length": 853, "reference_length": 1155}
{"bleu": 0.0, "precisions": [0.08737864077669903, 0.01951219512195122, 0.00980392156862745, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.169230769230769, "translation_length": 206, "reference_length": 65}
{"bleu": 0.0, "precisions": [0.005213764337851929, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 45.666666666666664, "translation_length": 959, "reference_length": 21}
{"bleu": 0.4618727573071787, "precisions": [0.48866498740554154, 0.45649432534678436, 0.4532828282828283, 0.450063211125158], "brevity_penalty": 1.0, "length_ratio": 1.8949880668257757, "translation_length": 794, "reference_length": 419}
{"bleu": 0.0, "precisions": [0.18932038834951456, 0.004878048780487805, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.4714285714285715, "translation_length": 206, "reference_length": 140}
{"bleu": 0.12242168195603138, "precisions": [0.13240418118466898, 0.12237762237762238, 0.11929824561403508, 0.11619718309859155], "brevity_penalty": 1.0, "length_ratio": 6.674418604651163, "translation_length": 287, "reference_length": 43}
{"error": "CUDA out of memory. Tried to allocate 1.50 GiB. GPU 0 has a total capacity of 10.75 GiB of which 1.35 GiB is free. Including non-PyTorch memory, this process has 9.40 GiB memory in use. Of the allocated memory 8.87 GiB is allocated by PyTorch, and 327.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 3.420868879266291e-07, "precisions": [0.358974358974359, 0.14705882352941177, 0.14022140221402213, 0.13703703703703704], "brevity_penalty": 1.916835009119318e-06, "length_ratio": 0.07059736229635376, "translation_length": 273, "reference_length": 3867}
{"bleu": 0.26824139256020607, "precisions": [0.2693467336683417, 0.2686116700201207, 0.2678751258811682, 0.26713709677419356], "brevity_penalty": 1.0, "length_ratio": 3.618181818181818, "translation_length": 995, "reference_length": 275}
{"bleu": 0.0, "precisions": [0.08169934640522876, 0.02618657937806874, 0.013114754098360656, 0.0], "brevity_penalty": 1.0, "length_ratio": 5.773584905660377, "translation_length": 612, "reference_length": 106}
{"bleu": 0.04181160429749226, "precisions": [0.051142546245919476, 0.04357298474945534, 0.03925845147219193, 0.034934497816593885], "brevity_penalty": 1.0, "length_ratio": 13.924242424242424, "translation_length": 919, "reference_length": 66}
{"error": "Unsloth: input length 241975 + max_new_tokens 1024 exceeds the maximum sequence length of 131072!\nYou will need to do long context extension by increasing the `max_seq_length` in `FastLanguageModel.from_pretrained`."}
{"bleu": 0.7611322544186286, "precisions": [0.8211382113821138, 0.819672131147541, 0.8181818181818182, 0.8166666666666667], "brevity_penalty": 0.9294421312368021, "length_ratio": 0.9318181818181818, "translation_length": 123, "reference_length": 132}
{"error": "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 280.69 MiB is free. Including non-PyTorch memory, this process has 10.47 GiB memory in use. Of the allocated memory 9.91 GiB is allocated by PyTorch, and 362.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.11146002267119895, "precisions": [0.1166077738515901, 0.11084905660377359, 0.10979929161747344, 0.10874704491725769], "brevity_penalty": 1.0, "length_ratio": 8.323529411764707, "translation_length": 849, "reference_length": 102}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 120.42857142857143, "translation_length": 843, "reference_length": 7}
{"bleu": 0.40925320786124664, "precisions": [0.4155844155844156, 0.408130081300813, 0.40716612377850164, 0.4061990212071778], "brevity_penalty": 1.0, "length_ratio": 2.3783783783783785, "translation_length": 616, "reference_length": 259}
{"bleu": 1.9299729942918552e-16, "precisions": [0.5128205128205128, 0.24675324675324675, 0.23684210526315788, 0.22666666666666666], "brevity_penalty": 6.722526505837248e-16, "length_ratio": 0.027827327863003924, "translation_length": 78, "reference_length": 2803}
{"bleu": 0.0, "precisions": [0.04484304932735426, 0.0, 0.0, 0.0], "brevity_penalty": 0.9822226946277374, "length_ratio": 0.9823788546255506, "translation_length": 223, "reference_length": 227}
{"bleu": 0.07313602010724818, "precisions": [0.08362369337979095, 0.07692307692307693, 0.07017543859649122, 0.06338028169014084], "brevity_penalty": 1.0, "length_ratio": 11.958333333333334, "translation_length": 287, "reference_length": 24}
{"bleu": 0.15223172555672337, "precisions": [0.15853658536585366, 0.15510204081632653, 0.15163934426229508, 0.1440329218106996], "brevity_penalty": 1.0, "length_ratio": 5.3478260869565215, "translation_length": 246, "reference_length": 46}
{"bleu": 0.6897741609138042, "precisions": [0.7121212121212122, 0.6888045540796964, 0.6825095057034221, 0.6761904761904762], "brevity_penalty": 1.0, "length_ratio": 1.2972972972972974, "translation_length": 528, "reference_length": 407}
{"bleu": 0.0, "precisions": [0.12033462033462033, 0.000643915003219575, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.5824847250509164, "translation_length": 1554, "reference_length": 982}
{"bleu": 0.10334489339546334, "precisions": [0.10629067245119306, 0.10434782608695652, 0.10239651416122005, 0.10043668122270742], "brevity_penalty": 1.0, "length_ratio": 8.232142857142858, "translation_length": 461, "reference_length": 56}
{"bleu": 0.20972746830421526, "precisions": [0.21629213483146068, 0.21180880974695407, 0.20919324577861162, 0.20187793427230047], "brevity_penalty": 1.0, "length_ratio": 4.413223140495868, "translation_length": 1068, "reference_length": 242}
{"bleu": 0.04853147260934299, "precisions": [0.05235602094240838, 0.049868766404199474, 0.04736842105263158, 0.044854881266490766], "brevity_penalty": 1.0, "length_ratio": 14.148148148148149, "translation_length": 382, "reference_length": 27}
{"bleu": 0.09698186288984552, "precisions": [0.19230769230769232, 0.09032258064516129, 0.07792207792207792, 0.06535947712418301], "brevity_penalty": 1.0, "length_ratio": 1.95, "translation_length": 156, "reference_length": 80}
{"bleu": 0.0, "precisions": [0.05660377358490566, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 7.395348837209302, "translation_length": 318, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.008159564823209429, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 39.392857142857146, "translation_length": 1103, "reference_length": 28}
{"bleu": 0.027451317017456605, "precisions": [0.029850746268656716, 0.02774813233724653, 0.026709401709401708, 0.025668449197860963], "brevity_penalty": 1.0, "length_ratio": 27.58823529411765, "translation_length": 938, "reference_length": 34}
{"bleu": 5.610671272851586e-50, "precisions": [0.5645161290322581, 0.17297297297297298, 0.10326086956521739, 0.09289617486338798], "brevity_penalty": 3.2071389091352195e-49, "length_ratio": 0.008876163206871868, "translation_length": 186, "reference_length": 20955}
{"bleu": 0.0, "precisions": [0.06878306878306878, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.19672131147541, "translation_length": 378, "reference_length": 61}
{"bleu": 0.013831259030551888, "precisions": [0.015681544028950542, 0.014492753623188406, 0.013301088270858524, 0.012106537530266344], "brevity_penalty": 1.0, "length_ratio": 39.476190476190474, "translation_length": 829, "reference_length": 21}
{"bleu": 0.02011741788585334, "precisions": [0.021589793915603533, 0.0206286836935167, 0.01966568338249754, 0.018700787401574805], "brevity_penalty": 1.0, "length_ratio": 35.13793103448276, "translation_length": 1019, "reference_length": 29}
{"bleu": 0.24441432692460408, "precisions": [0.2730496453900709, 0.24555160142348753, 0.2357142857142857, 0.22580645161290322], "brevity_penalty": 1.0, "length_ratio": 3.4814814814814814, "translation_length": 282, "reference_length": 81}
{"bleu": 3.0806231270978173e-07, "precisions": [0.45849056603773586, 0.1720226843100189, 0.13825757575757575, 0.11764705882352941], "brevity_penalty": 1.6277662418307366e-06, "length_ratio": 0.06979194100605741, "translation_length": 530, "reference_length": 7594}
{"bleu": 0.0, "precisions": [0.06326530612244897, 0.0040858018386108275, 0.0010224948875255625, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.3119143239625168, "translation_length": 980, "reference_length": 747}
{"bleu": 0.08865812010723298, "precisions": [0.1188118811881188, 0.09950248756218906, 0.08, 0.06532663316582915], "brevity_penalty": 1.0, "length_ratio": 5.9411764705882355, "translation_length": 202, "reference_length": 34}
{"error": "CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 218.69 MiB is free. Including non-PyTorch memory, this process has 10.53 GiB memory in use. Of the allocated memory 9.90 GiB is allocated by PyTorch, and 432.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.1864102045754634, "precisions": [0.20308788598574823, 0.19143876337693222, 0.18095238095238095, 0.17163289630512515], "brevity_penalty": 1.0, "length_ratio": 4.651933701657459, "translation_length": 842, "reference_length": 181}
{"bleu": 0.0011650613220757298, "precisions": [0.9142857142857143, 0.867816091954023, 0.8554913294797688, 0.8488372093023255], "brevity_penalty": 0.0013372461960775104, "length_ratio": 0.1312828207051763, "translation_length": 175, "reference_length": 1333}
{"bleu": 0.0, "precisions": [0.02753441802252816, 0.007518796992481203, 0.0037641154328732747, 0.0], "brevity_penalty": 1.0, "length_ratio": 17.755555555555556, "translation_length": 799, "reference_length": 45}
{"bleu": 0.03641472153047181, "precisions": [0.9835294117647059, 0.9717314487632509, 0.9610849056603774, 0.9504132231404959], "brevity_penalty": 0.03767255139512742, "length_ratio": 0.2337091009073412, "translation_length": 850, "reference_length": 3637}
{"bleu": 0.002995257088738101, "precisions": [0.71, 0.6432160804020101, 0.6313131313131313, 0.6192893401015228], "brevity_penalty": 0.004607821929992752, "length_ratio": 0.15673981191222572, "translation_length": 200, "reference_length": 1276}
{"bleu": 0.0643678974166947, "precisions": [0.078125, 0.06689834926151172, 0.06086956521739131, 0.053959965187119235], "brevity_penalty": 1.0, "length_ratio": 10.105263157894736, "translation_length": 1152, "reference_length": 114}
{"bleu": 0.1404470376023391, "precisions": [0.1566265060240964, 0.14634146341463414, 0.13580246913580246, 0.125], "brevity_penalty": 1.0, "length_ratio": 3.9523809523809526, "translation_length": 83, "reference_length": 21}
{"error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 276.69 MiB is free. Including non-PyTorch memory, this process has 10.47 GiB memory in use. Of the allocated memory 9.84 GiB is allocated by PyTorch, and 437.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.027517113090027596, "precisions": [0.041312272174969626, 0.029197080291970802, 0.024360535931790498, 0.01951219512195122], "brevity_penalty": 1.0, "length_ratio": 13.063492063492063, "translation_length": 823, "reference_length": 63}
{"bleu": 0.02766366275340203, "precisions": [0.0308839190628328, 0.02771855010660981, 0.026680896478121666, 0.02564102564102564], "brevity_penalty": 1.0, "length_ratio": 27.61764705882353, "translation_length": 939, "reference_length": 34}
{"bleu": 3.2848225084192735e-11, "precisions": [0.8210526315789474, 0.7407407407407407, 0.7340425531914894, 0.7272727272727273], "brevity_penalty": 4.3515899588147174e-11, "length_ratio": 0.04022866821935211, "translation_length": 190, "reference_length": 4723}
{"bleu": 0.0, "precisions": [0.12903225806451613, 0.0, 0.0, 0.0], "brevity_penalty": 0.6790253796134038, "length_ratio": 0.7209302325581395, "translation_length": 31, "reference_length": 43}
{"error": "CUDA out of memory. Tried to allocate 248.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 218.69 MiB is free. Including non-PyTorch memory, this process has 10.53 GiB memory in use. Of the allocated memory 9.97 GiB is allocated by PyTorch, and 356.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.018507065315655404, "precisions": [0.020202020202020204, 0.019101123595505618, 0.01799775028121485, 0.016891891891891893], "brevity_penalty": 1.0, "length_ratio": 35.64, "translation_length": 891, "reference_length": 25}
{"bleu": 3.5834201018873244e-07, "precisions": [0.6267995570321152, 0.328159645232816, 0.23640399556048836, 0.1711111111111111], "brevity_penalty": 1.1864815959204358e-06, "length_ratio": 0.06828493647912885, "translation_length": 903, "reference_length": 13224}
{"bleu": 0.002458543412293202, "precisions": [0.6666666666666666, 0.4682713347921225, 0.4194961664841183, 0.4144736842105263], "brevity_penalty": 0.005093544013985104, "length_ratio": 0.15924121127741037, "translation_length": 915, "reference_length": 5746}
{"bleu": 0.32350609753115434, "precisions": [0.33962264150943394, 0.3291139240506329, 0.3184713375796178, 0.3076923076923077], "brevity_penalty": 1.0, "length_ratio": 2.6065573770491803, "translation_length": 159, "reference_length": 61}
{"bleu": 0.4201326124031386, "precisions": [0.9035532994923858, 0.8979591836734694, 0.8923076923076924, 0.8865979381443299], "brevity_penalty": 0.4693787920014868, "length_ratio": 0.569364161849711, "translation_length": 197, "reference_length": 346}
{"bleu": 0.0, "precisions": [0.015151515151515152, 0.0011668611435239206, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 29.586206896551722, "translation_length": 858, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.05319148936170213, 0.0, 0.0, 0.0], "brevity_penalty": 0.7345401379008187, "length_ratio": 0.7642276422764228, "translation_length": 94, "reference_length": 123}
{"error": "CUDA out of memory. Tried to allocate 304.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 80.69 MiB is free. Including non-PyTorch memory, this process has 10.66 GiB memory in use. Of the allocated memory 9.99 GiB is allocated by PyTorch, and 480.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 40.69 MiB is free. Including non-PyTorch memory, this process has 10.70 GiB memory in use. Of the allocated memory 10.05 GiB is allocated by PyTorch, and 460.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 9.007877532672936e-07, "precisions": [0.7530120481927711, 0.6072507552870091, 0.5666666666666667, 0.5258358662613982], "brevity_penalty": 1.482639300890043e-06, "length_ratio": 0.06934001670843776, "translation_length": 332, "reference_length": 4788}
{"bleu": 1.0026509485122883e-07, "precisions": [0.424, 0.24497991967871485, 0.2217741935483871, 0.2145748987854251], "brevity_penalty": 3.781405065289377e-07, "length_ratio": 0.06333924499619964, "translation_length": 250, "reference_length": 3947}
{"bleu": 5.670513073270871e-07, "precisions": [0.8637873754152824, 0.7633333333333333, 0.7491638795986622, 0.7449664429530202], "brevity_penalty": 7.280541821794729e-07, "length_ratio": 0.06608122941822174, "translation_length": 301, "reference_length": 4555}
{"bleu": 0.4985616492902614, "precisions": [0.5027932960893855, 0.5, 0.4971751412429379, 0.4943181818181818], "brevity_penalty": 1.0, "length_ratio": 1.8453608247422681, "translation_length": 179, "reference_length": 97}
{"bleu": 0.06951071702697166, "precisions": [0.277720207253886, 0.07053941908713693, 0.04776739356178609, 0.02494802494802495], "brevity_penalty": 1.0, "length_ratio": 1.5976821192052981, "translation_length": 965, "reference_length": 604}
{"bleu": 0.0, "precisions": [0.08123791102514506, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 5.068627450980392, "translation_length": 517, "reference_length": 102}
{"bleu": 0.57102436861364, "precisions": [0.574468085106383, 0.5721925133689839, 0.5698924731182796, 0.5675675675675675], "brevity_penalty": 1.0, "length_ratio": 1.6347826086956523, "translation_length": 188, "reference_length": 115}
{"bleu": 0.0, "precisions": [0.25225225225225223, 0.03636363636363636, 0.01834862385321101, 0.0], "brevity_penalty": 0.7495454759063911, "length_ratio": 0.7762237762237763, "translation_length": 111, "reference_length": 143}
{"bleu": 0.006667082992312013, "precisions": [0.41711711711711713, 0.2651036970243463, 0.2328519855595668, 0.21138211382113822], "brevity_penalty": 0.024545979469724692, "length_ratio": 0.21244019138755982, "translation_length": 1110, "reference_length": 5225}
{"bleu": 3.863804283221494e-06, "precisions": [0.9452554744525548, 0.9267399267399268, 0.9227941176470589, 0.922509225092251], "brevity_penalty": 4.157856217279912e-06, "length_ratio": 0.07467974925047698, "translation_length": 274, "reference_length": 3669}
{"bleu": 6.155211988555288e-14, "precisions": [0.2490118577075099, 0.027777777777777776, 0.01195219123505976, 0.008], "brevity_penalty": 2.158386683588973e-12, "length_ratio": 0.03589161583203291, "translation_length": 253, "reference_length": 7049}
{"bleu": 0.00017898756801653805, "precisions": [0.441747572815534, 0.24878048780487805, 0.19607843137254902, 0.15270935960591134], "brevity_penalty": 0.0007473110009456005, "length_ratio": 0.12196566015393724, "translation_length": 206, "reference_length": 1689}
{"bleu": 0.7308462286283286, "precisions": [0.88671875, 0.8470588235294118, 0.8267716535433071, 0.8063241106719368], "brevity_penalty": 0.8688150562628432, "length_ratio": 0.8767123287671232, "translation_length": 256, "reference_length": 292}
{"bleu": 0.14132531712717103, "precisions": [0.23985239852398524, 0.12199630314232902, 0.11851851851851852, 0.1150278293135436], "brevity_penalty": 1.0, "length_ratio": 1.0168855534709194, "translation_length": 542, "reference_length": 533}
{"error": "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 258.69 MiB is free. Including non-PyTorch memory, this process has 10.49 GiB memory in use. Of the allocated memory 9.81 GiB is allocated by PyTorch, and 480.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 32.69 MiB is free. Including non-PyTorch memory, this process has 10.71 GiB memory in use. Of the allocated memory 10.06 GiB is allocated by PyTorch, and 452.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 166.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 78.69 MiB is free. Including non-PyTorch memory, this process has 10.67 GiB memory in use. Of the allocated memory 9.92 GiB is allocated by PyTorch, and 552.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.011594504811215246, "precisions": [0.039735099337748346, 0.008839779005524863, 0.007743362831858407, 0.006644518272425249], "brevity_penalty": 1.0, "length_ratio": 11.185185185185185, "translation_length": 906, "reference_length": 81}
{"bleu": 0.08073127663220792, "precisions": [0.30275229357798167, 0.09387755102040816, 0.054136874361593465, 0.027607361963190184], "brevity_penalty": 1.0, "length_ratio": 1.0628385698808234, "translation_length": 981, "reference_length": 923}
{"bleu": 0.044921346868775705, "precisions": [0.5017667844522968, 0.29245283018867924, 0.256198347107438, 0.23995271867612294], "brevity_penalty": 0.1457598239900897, "length_ratio": 0.3417874396135266, "translation_length": 849, "reference_length": 2484}
{"bleu": 0.35375506225370973, "precisions": [0.5361744301288405, 0.3888888888888889, 0.3644488579940417, 0.34095427435387676], "brevity_penalty": 0.8817319372039844, "length_ratio": 0.8882042253521126, "translation_length": 1009, "reference_length": 1136}
{"bleu": 0.0, "precisions": [0.005813953488372093, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 9.45054945054945, "translation_length": 860, "reference_length": 91}
{"bleu": 0.06272579842487798, "precisions": [0.08117249154453213, 0.060948081264108354, 0.0576271186440678, 0.05429864253393665], "brevity_penalty": 1.0, "length_ratio": 7.990990990990991, "translation_length": 887, "reference_length": 111}
{"bleu": 0.0, "precisions": [0.002902757619738752, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 28.708333333333332, "translation_length": 689, "reference_length": 24}
{"bleu": 0.021856770721122562, "precisions": [0.03799019607843137, 0.022085889570552148, 0.018427518427518427, 0.014760147601476014], "brevity_penalty": 1.0, "length_ratio": 20.4, "translation_length": 816, "reference_length": 40}
{"bleu": 0.0, "precisions": [0.3119266055045872, 0.05069124423963134, 0.018518518518518517, 0.0], "brevity_penalty": 3.842471750125922e-15, "length_ratio": 0.029246042393345856, "translation_length": 218, "reference_length": 7454}
{"bleu": 1.751781167701329e-05, "precisions": [0.9988452655889145, 0.9872832369942196, 0.9791666666666666, 0.9721900347624566], "brevity_penalty": 1.779684066072189e-05, "length_ratio": 0.08377672438812034, "translation_length": 866, "reference_length": 10337}
{"bleu": 0.03531265190609549, "precisions": [0.10197368421052631, 0.033003300330033, 0.023178807947019868, 0.019933554817275746], "brevity_penalty": 1.0, "length_ratio": 3.234042553191489, "translation_length": 304, "reference_length": 94}
{"error": "CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 98.69 MiB is free. Including non-PyTorch memory, this process has 10.65 GiB memory in use. Of the allocated memory 9.99 GiB is allocated by PyTorch, and 462.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 58.69 MiB is free. Including non-PyTorch memory, this process has 10.69 GiB memory in use. Of the allocated memory 10.04 GiB is allocated by PyTorch, and 445.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.07417216996949606, "precisions": [0.07582938388625593, 0.07473309608540925, 0.07363420427553444, 0.07253269916765755], "brevity_penalty": 1.0, "length_ratio": 11.887323943661972, "translation_length": 844, "reference_length": 71}
{"bleu": 0.0, "precisions": [0.02403846153846154, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 9.904761904761905, "translation_length": 208, "reference_length": 21}
{"bleu": 4.843538626403197e-05, "precisions": [0.6276595744680851, 0.41935483870967744, 0.3804347826086957, 0.3626373626373626], "brevity_penalty": 0.00011095531794566167, "length_ratio": 0.09894736842105263, "translation_length": 94, "reference_length": 950}
{"bleu": 0.049911565025411296, "precisions": [0.5929203539823009, 0.4732142857142857, 0.4594594594594595, 0.44545454545454544], "brevity_penalty": 0.10195886404613562, "length_ratio": 0.3045822102425876, "translation_length": 113, "reference_length": 371}
{"bleu": 0.016801936015399546, "precisions": [0.4279141104294479, 0.0629800307219662, 0.055384615384615386, 0.05084745762711865], "brevity_penalty": 0.18001341080763839, "length_ratio": 0.36836158192090396, "translation_length": 652, "reference_length": 1770}
{"bleu": 0.3784070606629313, "precisions": [0.9148629148629148, 0.8945086705202312, 0.894356005788712, 0.8942028985507247], "brevity_penalty": 0.4207144818306733, "length_ratio": 0.5359628770301624, "translation_length": 693, "reference_length": 1293}
{"bleu": 0.0, "precisions": [0.06635071090047394, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.906976744186046, "translation_length": 211, "reference_length": 43}
{"bleu": 0.0006994994746075039, "precisions": [0.4586693548387097, 0.10494450050454086, 0.07777777777777778, 0.05156723963599596], "brevity_penalty": 0.00593424109193165, "length_ratio": 0.163211582757486, "translation_length": 992, "reference_length": 6078}
{"bleu": 0.05358536423904161, "precisions": [0.20320855614973263, 0.07526881720430108, 0.043243243243243246, 0.021739130434782608], "brevity_penalty": 0.8701954536871993, "length_ratio": 0.8779342723004695, "translation_length": 187, "reference_length": 213}
{"bleu": 0.0, "precisions": [0.002176278563656148, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 70.6923076923077, "translation_length": 919, "reference_length": 13}
{"bleu": 0.017885780782498455, "precisions": [0.031425364758698095, 0.017977528089887642, 0.014623172103487065, 0.012387387387387387], "brevity_penalty": 1.0, "length_ratio": 6.456521739130435, "translation_length": 891, "reference_length": 138}
{"bleu": 0.0, "precisions": [0.00404040404040404, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 41.25, "translation_length": 990, "reference_length": 24}
{"bleu": 0.0, "precisions": [0.06666666666666667, 0.0, 0.0, 0.0], "brevity_penalty": 0.1266071027890836, "length_ratio": 0.32608695652173914, "translation_length": 15, "reference_length": 46}
{"bleu": 0.11248869066424795, "precisions": [0.1328191945158526, 0.10806174957118353, 0.10643776824034334, 0.10481099656357389], "brevity_penalty": 1.0, "length_ratio": 4.290441176470588, "translation_length": 1167, "reference_length": 272}
{"bleu": 0.3121173188036847, "precisions": [0.9914004914004914, 0.990159901599016, 0.9901477832512315, 0.9901356350184957], "brevity_penalty": 0.31512334203180986, "length_ratio": 0.4640820980615735, "translation_length": 814, "reference_length": 1754}
{"bleu": 0.059596574232930244, "precisions": [0.06437768240343347, 0.06236559139784946, 0.05818965517241379, 0.05399568034557235], "brevity_penalty": 1.0, "length_ratio": 15.533333333333333, "translation_length": 466, "reference_length": 30}
{"bleu": 0.11401614125185468, "precisions": [0.11927710843373494, 0.11338962605548854, 0.11231884057971014, 0.11124546553808948], "brevity_penalty": 1.0, "length_ratio": 8.137254901960784, "translation_length": 830, "reference_length": 102}
{"error": "CUDA out of memory. Tried to allocate 504.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 396.69 MiB is free. Including non-PyTorch memory, this process has 10.36 GiB memory in use. Of the allocated memory 9.77 GiB is allocated by PyTorch, and 389.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.39205870869577936, "precisions": [0.42953020134228187, 0.40540540540540543, 0.38095238095238093, 0.3561643835616438], "brevity_penalty": 1.0, "length_ratio": 2.0135135135135136, "translation_length": 149, "reference_length": 74}
{"bleu": 0.0, "precisions": [0.07865168539325842, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.5428571428571427, "translation_length": 89, "reference_length": 35}
{"bleu": 0.0, "precisions": [0.10084033613445378, 0.01694915254237288, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.103448275862069, "translation_length": 119, "reference_length": 29}
{"bleu": 0.5562312462265013, "precisions": [0.5686274509803921, 0.5589123867069486, 0.5521936459909228, 0.5454545454545454], "brevity_penalty": 1.0, "length_ratio": 1.753968253968254, "translation_length": 663, "reference_length": 378}
{"bleu": 0.0, "precisions": [0.027906976744186046, 0.00186219739292365, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 13.271604938271604, "translation_length": 1075, "reference_length": 81}
{"bleu": 0.0, "precisions": [0.10810810810810811, 0.00909090909090909, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.22, "translation_length": 111, "reference_length": 50}
{"bleu": 0.0, "precisions": [0.033707865168539325, 0.011363636363636364, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.357142857142857, "translation_length": 89, "reference_length": 14}
{"bleu": 3.0357460649451624e-06, "precisions": [0.4207708779443255, 0.31189710610932475, 0.30150214592274677, 0.2996777658431794], "brevity_penalty": 9.199515456751404e-06, "length_ratio": 0.0793880152996175, "translation_length": 934, "reference_length": 11765}
{"bleu": 0.0, "precisions": [0.17177914110429449, 0.0010235414534288639, 0.0, 0.0], "brevity_penalty": 0.00038867744979987376, "length_ratio": 0.11295911295911296, "translation_length": 978, "reference_length": 8658}
{"bleu": 0.0, "precisions": [0.009018036072144289, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 32.193548387096776, "translation_length": 998, "reference_length": 31}
{"bleu": 0.0038871526593692823, "precisions": [0.7053571428571429, 0.6155810983397191, 0.5843989769820972, 0.5633802816901409], "brevity_penalty": 0.006321646957670748, "length_ratio": 0.16491375683634835, "translation_length": 784, "reference_length": 4754}
{"bleu": 0.031655983911173344, "precisions": [0.04667328699106256, 0.02982107355864811, 0.027860696517412936, 0.025896414342629483], "brevity_penalty": 1.0, "length_ratio": 9.5, "translation_length": 1007, "reference_length": 106}
{"bleu": 0.18602080642245603, "precisions": [0.922077922077922, 0.9130434782608695, 0.9126637554585153, 0.9122807017543859], "brevity_penalty": 0.2032997896403625, "length_ratio": 0.38564273789649417, "translation_length": 231, "reference_length": 599}
{"bleu": 0.008389136021760906, "precisions": [0.015277777777777777, 0.008344923504867872, 0.006963788300835654, 0.005578800557880056], "brevity_penalty": 1.0, "length_ratio": 51.42857142857143, "translation_length": 720, "reference_length": 14}
{"bleu": 0.0, "precisions": [0.17307692307692307, 0.0, 0.0, 0.0], "brevity_penalty": 0.14337270762769766, "length_ratio": 0.33986928104575165, "translation_length": 52, "reference_length": 153}
{"bleu": 0.0, "precisions": [0.00819672131147541, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.777777777777778, "translation_length": 122, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.05263157894736842, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.885714285714286, "translation_length": 171, "reference_length": 35}
{"bleu": 0.02975973387714559, "precisions": [0.43539630836047777, 0.25217391304347825, 0.20783460282916214, 0.1786492374727669], "brevity_penalty": 0.11777498635533175, "length_ratio": 0.3185748875821515, "translation_length": 921, "reference_length": 2891}
{"bleu": 0.2507312868292768, "precisions": [0.51, 0.3634085213032581, 0.32663316582914576, 0.28967254408060455], "brevity_penalty": 0.6890096515578809, "length_ratio": 0.7285974499089253, "translation_length": 400, "reference_length": 549}
{"bleu": 4.151533312718176e-06, "precisions": [0.24041811846689895, 0.07441860465116279, 0.05820721769499418, 0.05128205128205128], "brevity_penalty": 4.856359075584466e-05, "length_ratio": 0.09146924466163817, "translation_length": 861, "reference_length": 9413}
{"bleu": 0.03152815676029721, "precisions": [0.034954407294832825, 0.0319634703196347, 0.03048780487804878, 0.02900763358778626], "brevity_penalty": 1.0, "length_ratio": 22.689655172413794, "translation_length": 658, "reference_length": 29}
{"bleu": 0.06137442277140537, "precisions": [0.30988786952089703, 0.1846938775510204, 0.1491317671092952, 0.12576687116564417], "brevity_penalty": 0.33906975040884235, "length_ratio": 0.480411361410382, "translation_length": 981, "reference_length": 2042}
{"bleu": 0.0, "precisions": [0.053518334985133795, 0.00496031746031746, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 7.94488188976378, "translation_length": 1009, "reference_length": 127}
{"bleu": 0.2774989543373628, "precisions": [0.2847682119205298, 0.28, 0.2751677852348993, 0.2702702702702703], "brevity_penalty": 1.0, "length_ratio": 3.02, "translation_length": 151, "reference_length": 50}
{"bleu": 0.007290532200987469, "precisions": [0.01045751633986928, 0.007853403141361256, 0.00655307994757536, 0.005249343832020997], "brevity_penalty": 1.0, "length_ratio": 95.625, "translation_length": 765, "reference_length": 8}
{"bleu": 0.7681140495106317, "precisions": [0.7921108742004265, 0.7705442902881536, 0.7596153846153846, 0.7508021390374332], "brevity_penalty": 1.0, "length_ratio": 1.2197659297789336, "translation_length": 938, "reference_length": 769}
{"bleu": 0.13640422388312504, "precisions": [0.4306569343065693, 0.3088235294117647, 0.2962962962962963, 0.2835820895522388], "brevity_penalty": 0.419532980032414, "length_ratio": 0.53515625, "translation_length": 137, "reference_length": 256}
{"bleu": 2.3027866966339003e-08, "precisions": [0.782258064516129, 0.6829268292682927, 0.6557377049180327, 0.6528925619834711], "brevity_penalty": 3.3298884617735764e-08, "length_ratio": 0.054891544931385566, "translation_length": 124, "reference_length": 2259}
{"bleu": 0.0, "precisions": [0.03636363636363636, 0.012195121951219513, 0.006134969325153374, 0.0], "brevity_penalty": 1.0, "length_ratio": 9.705882352941176, "translation_length": 165, "reference_length": 17}
{"bleu": 0.03774135845930576, "precisions": [0.044642857142857144, 0.040268456375838924, 0.03587443946188341, 0.03146067415730337], "brevity_penalty": 1.0, "length_ratio": 21.333333333333332, "translation_length": 448, "reference_length": 21}
{"bleu": 0.0, "precisions": [0.17567567567567569, 0.0136986301369863, 0.0, 0.0], "brevity_penalty": 0.00030108796056705224, "length_ratio": 0.10979228486646884, "translation_length": 74, "reference_length": 674}
{"bleu": 0.0, "precisions": [0.2535211267605634, 0.07142857142857142, 0.028985507246376812, 0.0], "brevity_penalty": 0.009056927430866746, "length_ratio": 0.17530864197530865, "translation_length": 71, "reference_length": 405}
{"bleu": 0.12341817432473641, "precisions": [0.25876288659793817, 0.13415892672858618, 0.09504132231404959, 0.0703205791106515], "brevity_penalty": 1.0, "length_ratio": 2.5797872340425534, "translation_length": 970, "reference_length": 376}
{"bleu": 0.013816650210796321, "precisions": [0.018730489073881373, 0.013541666666666667, 0.01251303441084463, 0.011482254697286013], "brevity_penalty": 1.0, "length_ratio": 15.754098360655737, "translation_length": 961, "reference_length": 61}
{"error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 258.69 MiB is free. Including non-PyTorch memory, this process has 10.49 GiB memory in use. Of the allocated memory 9.79 GiB is allocated by PyTorch, and 501.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.6449964147315165, "precisions": [0.9381563593932322, 0.9182242990654206, 0.9099415204678363, 0.9039812646370023], "brevity_penalty": 0.7030044442586033, "length_ratio": 0.7394305435720449, "translation_length": 857, "reference_length": 1159}
{"bleu": 0.14657826265217572, "precisions": [0.6514619883040935, 0.5526932084309133, 0.5146541617819461, 0.4765258215962441], "brevity_penalty": 0.26889070248870633, "length_ratio": 0.4322548028311426, "translation_length": 855, "reference_length": 1978}
{"bleu": 0.0, "precisions": [0.01757469244288225, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 16.257142857142856, "translation_length": 569, "reference_length": 35}
{"bleu": 0.4966262650292515, "precisions": [0.5109489051094891, 0.49415204678362573, 0.49194729136163984, 0.4897360703812317], "brevity_penalty": 1.0, "length_ratio": 1.793193717277487, "translation_length": 685, "reference_length": 382}
{"bleu": 0.0, "precisions": [0.05517241379310345, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.67741935483871, "translation_length": 145, "reference_length": 31}
{"bleu": 0.03314792279541704, "precisions": [0.03474484256243214, 0.03369565217391304, 0.03264417845484222, 0.03159041394335512], "brevity_penalty": 1.0, "length_ratio": 23.615384615384617, "translation_length": 921, "reference_length": 39}
{"bleu": 0.0, "precisions": [0.09262948207171315, 0.006979062811565304, 0.001996007984031936, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.207667731629393, "translation_length": 1004, "reference_length": 313}
{"bleu": 1.4016888729451954e-05, "precisions": [0.5234375, 0.43137254901960786, 0.42913385826771655, 0.4268774703557312], "brevity_penalty": 3.1081236463601456e-05, "length_ratio": 0.08788190868520426, "translation_length": 256, "reference_length": 2913}
{"bleu": 0.1073529892461746, "precisions": [0.11320754716981132, 0.10636182902584493, 0.1054726368159204, 0.10458167330677291], "brevity_penalty": 1.0, "length_ratio": 7.929133858267717, "translation_length": 1007, "reference_length": 127}
{"bleu": 0.272594625081231, "precisions": [0.28125, 0.2755905511811024, 0.2698412698412698, 0.264], "brevity_penalty": 1.0, "length_ratio": 2.9767441860465116, "translation_length": 128, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.047619047619047616, 0.00954653937947494, 0.004784688995215311, 0.0], "brevity_penalty": 1.0, "length_ratio": 9.767441860465116, "translation_length": 420, "reference_length": 43}
{"bleu": 0.10151819441086926, "precisions": [0.10976948408342481, 0.1043956043956044, 0.09900990099009901, 0.09361233480176212], "brevity_penalty": 1.0, "length_ratio": 8.133928571428571, "translation_length": 911, "reference_length": 112}
{"bleu": 7.942133849109843e-20, "precisions": [0.7272727272727273, 0.5473684210526316, 0.4823943661971831, 0.43109540636042404], "brevity_penalty": 1.480638494940595e-19, "length_ratio": 0.02254453728519628, "translation_length": 286, "reference_length": 12686}
{"error": "CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 168.69 MiB is free. Including non-PyTorch memory, this process has 10.58 GiB memory in use. Of the allocated memory 9.93 GiB is allocated by PyTorch, and 456.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0079585242986188, "precisions": [0.01270772238514174, 0.007827788649706457, 0.0068560235063663075, 0.0058823529411764705], "brevity_penalty": 1.0, "length_ratio": 37.888888888888886, "translation_length": 1023, "reference_length": 27}
{"bleu": 0.0, "precisions": [0.06766917293233082, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 5.911111111111111, "translation_length": 266, "reference_length": 45}
{"bleu": 0.0, "precisions": [0.02240325865580448, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 7.383458646616542, "translation_length": 982, "reference_length": 133}
{"bleu": 0.051064139141322136, "precisions": [0.6042780748663101, 0.5067024128686327, 0.5026881720430108, 0.5013477088948787], "brevity_penalty": 0.09688557858917293, "length_ratio": 0.29991980753809144, "translation_length": 374, "reference_length": 1247}
{"error": "CUDA out of memory. Tried to allocate 244.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 96.69 MiB is free. Including non-PyTorch memory, this process has 10.65 GiB memory in use. Of the allocated memory 9.92 GiB is allocated by PyTorch, and 534.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.06857142857142857, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.5714285714285716, "translation_length": 175, "reference_length": 49}
{"bleu": 0.03728024973949057, "precisions": [0.04923413566739606, 0.03504928806133625, 0.03399122807017544, 0.03293084522502744], "brevity_penalty": 1.0, "length_ratio": 13.246376811594203, "translation_length": 914, "reference_length": 69}
{"bleu": 0.0, "precisions": [0.023185483870967742, 0.0010090817356205853, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 14.805970149253731, "translation_length": 992, "reference_length": 67}
{"bleu": 0.0, "precisions": [0.1326530612244898, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.0425531914893618, "translation_length": 196, "reference_length": 188}
{"bleu": 0.12422025740041291, "precisions": [0.21100917431192662, 0.11734693877551021, 0.10112359550561797, 0.0950920245398773], "brevity_penalty": 1.0, "length_ratio": 2.165562913907285, "translation_length": 981, "reference_length": 453}
{"error": "Unsloth: input length 307022 + max_new_tokens 1024 exceeds the maximum sequence length of 131072!\nYou will need to do long context extension by increasing the `max_seq_length` in `FastLanguageModel.from_pretrained`."}
{"error": "Unsloth: input length 661167 + max_new_tokens 1024 exceeds the maximum sequence length of 131072!\nYou will need to do long context extension by increasing the `max_seq_length` in `FastLanguageModel.from_pretrained`."}
{"bleu": 6.490843575320691e-10, "precisions": [0.8155339805825242, 0.696078431372549, 0.6138613861386139, 0.54], "brevity_penalty": 9.855077969775608e-10, "length_ratio": 0.04600267976775346, "translation_length": 103, "reference_length": 2239}
{"bleu": 0.0, "precisions": [0.0975609756097561, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.8222222222222222, "translation_length": 82, "reference_length": 45}
{"bleu": 0.0, "precisions": [0.042111506524317915, 0.0017804154302670622, 0.0005938242280285036, 0.0], "brevity_penalty": 1.0, "length_ratio": 12.129496402877697, "translation_length": 1686, "reference_length": 139}
{"bleu": 0.0, "precisions": [0.01216089803554724, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 7.032894736842105, "translation_length": 1069, "reference_length": 152}
{"bleu": 0.04046213474149278, "precisions": [0.04535637149028078, 0.04, 0.03896103896103896, 0.03791982665222102], "brevity_penalty": 1.0, "length_ratio": 20.57777777777778, "translation_length": 926, "reference_length": 45}
{"error": "Unsloth: input length 241184 + max_new_tokens 1024 exceeds the maximum sequence length of 131072!\nYou will need to do long context extension by increasing the `max_seq_length` in `FastLanguageModel.from_pretrained`."}
{"bleu": 0.015819447224530173, "precisions": [0.01793103448275862, 0.016574585635359115, 0.015214384508990318, 0.013850415512465374], "brevity_penalty": 1.0, "length_ratio": 34.523809523809526, "translation_length": 725, "reference_length": 21}
{"bleu": 0.6128990955361217, "precisions": [0.811088295687885, 0.7564234326824255, 0.7479423868312757, 0.7435633367662204], "brevity_penalty": 0.8019257794598402, "length_ratio": 0.8191757779646762, "translation_length": 974, "reference_length": 1189}
{"error": "CUDA out of memory. Tried to allocate 1.41 GiB. GPU 0 has a total capacity of 10.75 GiB of which 1.31 GiB is free. Including non-PyTorch memory, this process has 9.44 GiB memory in use. Of the allocated memory 8.84 GiB is allocated by PyTorch, and 404.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0388655676682954, "precisions": [0.7777777777777778, 0.6551724137931034, 0.591304347826087, 0.5614035087719298], "brevity_penalty": 0.06060251995116927, "length_ratio": 0.26292134831460673, "translation_length": 117, "reference_length": 445}
{"bleu": 0.0, "precisions": [0.19148936170212766, 0.0, 0.0, 0.0], "brevity_penalty": 0.2303661898473039, "length_ratio": 0.4051724137931034, "translation_length": 47, "reference_length": 116}
{"bleu": 0.0033474734439613257, "precisions": [0.0064995357474466105, 0.0037174721189591076, 0.0027906976744186047, 0.00186219739292365], "brevity_penalty": 1.0, "length_ratio": 67.3125, "translation_length": 1077, "reference_length": 16}
{"bleu": 0.00029590099322680563, "precisions": [0.4777777777777778, 0.03064066852367688, 0.013966480446927373, 0.0056022408963585435], "brevity_penalty": 0.009044887884114838, "length_ratio": 0.17526777020447906, "translation_length": 360, "reference_length": 2054}
{"bleu": 0.08094970600963317, "precisions": [0.10177514792899409, 0.08056872037914692, 0.07473309608540925, 0.07007125890736342], "brevity_penalty": 1.0, "length_ratio": 6.1231884057971016, "translation_length": 845, "reference_length": 138}
{"bleu": 1.568562063574002e-22, "precisions": [0.5105263157894737, 0.19047619047619047, 0.12234042553191489, 0.0855614973262032], "brevity_penalty": 8.78162543297525e-22, "length_ratio": 0.020208466283769412, "translation_length": 190, "reference_length": 9402}
{"bleu": 0.0, "precisions": [0.011988011988011988, 0.002, 0.001001001001001001, 0.0], "brevity_penalty": 1.0, "length_ratio": 32.29032258064516, "translation_length": 1001, "reference_length": 31}
{"bleu": 0.0, "precisions": [0.03875968992248062, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 8.6, "translation_length": 258, "reference_length": 30}
{"bleu": 0.0, "precisions": [1.0, 0.0, 0.0, 0.0], "brevity_penalty": 0.0, "length_ratio": 6.678242286630158e-05, "translation_length": 1, "reference_length": 14974}
{"bleu": 0.0, "precisions": [0.08653846153846154, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.622222222222222, "translation_length": 208, "reference_length": 45}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 24.0, "translation_length": 168, "reference_length": 7}
{"bleu": 0.0, "precisions": [0.1103448275862069, 0.0, 0.0, 0.0], "brevity_penalty": 0.21334865230243835, "length_ratio": 0.39295392953929537, "translation_length": 145, "reference_length": 369}
{"bleu": 0.4598029235908175, "precisions": [0.5044642857142857, 0.45739910313901344, 0.44594594594594594, 0.4343891402714932], "brevity_penalty": 1.0, "length_ratio": 1.160621761658031, "translation_length": 224, "reference_length": 193}
{"bleu": 0.02160844966164622, "precisions": [0.027422303473491772, 0.023809523809523808, 0.02018348623853211, 0.016544117647058824], "brevity_penalty": 1.0, "length_ratio": 36.46666666666667, "translation_length": 547, "reference_length": 15}
{"bleu": 0.0, "precisions": [0.001949317738791423, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 48.857142857142854, "translation_length": 1026, "reference_length": 21}
{"bleu": 0.017709350494380018, "precisions": [0.020792079207920793, 0.018830525272547076, 0.016865079365079364, 0.014895729890764648], "brevity_penalty": 1.0, "length_ratio": 34.827586206896555, "translation_length": 1010, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.23717948717948717, 0.01935483870967742, 0.006493506493506494, 0.0], "brevity_penalty": 0.6634801052198983, "length_ratio": 0.7090909090909091, "translation_length": 156, "reference_length": 220}
{"bleu": 0.10071799942327922, "precisions": [0.11331444759206799, 0.09943181818181818, 0.09686609686609686, 0.09428571428571429], "brevity_penalty": 1.0, "length_ratio": 8.209302325581396, "translation_length": 353, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.17204301075268819, 0.021739130434782608, 0.01098901098901099, 0.0], "brevity_penalty": 0.14128314984652754, "length_ratio": 0.3381818181818182, "translation_length": 93, "reference_length": 275}
{"bleu": 0.012756910737634195, "precisions": [0.04205607476635514, 0.014084507042253521, 0.009433962264150943, 0.004739336492890996], "brevity_penalty": 1.0, "length_ratio": 11.88888888888889, "translation_length": 214, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.19148936170212766, 0.0, 0.0, 0.0], "brevity_penalty": 9.560177712212092e-05, "length_ratio": 0.0975103734439834, "translation_length": 94, "reference_length": 964}
{"bleu": 0.28060855416197433, "precisions": [0.43315508021390375, 0.2570281124497992, 0.24262734584450402, 0.2295302013422819], "brevity_penalty": 1.0, "length_ratio": 1.3800738007380073, "translation_length": 748, "reference_length": 542}
{"bleu": 2.7567399599288857e-11, "precisions": [0.5277777777777778, 0.3380281690140845, 0.32857142857142857, 0.3188405797101449], "brevity_penalty": 7.455794971071121e-11, "length_ratio": 0.041119360365505425, "translation_length": 72, "reference_length": 1751}
{"bleu": 0.04063284624713107, "precisions": [0.1868629671574179, 0.02834467120181406, 0.02383654937570942, 0.02159090909090909], "brevity_penalty": 1.0, "length_ratio": 2.597058823529412, "translation_length": 883, "reference_length": 340}
{"bleu": 0.0, "precisions": [0.0910209102091021, 0.0049261083743842365, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.1291666666666667, "translation_length": 813, "reference_length": 720}
{"bleu": 0.020285239613532784, "precisions": [0.7466666666666667, 0.6363636363636364, 0.6058981233243967, 0.5806451612903226], "brevity_penalty": 0.031724479673501, "length_ratio": 0.22468544038346316, "translation_length": 375, "reference_length": 1669}
{"bleu": 0.012043216760695906, "precisions": [0.043121149897330596, 0.014388489208633094, 0.00823045267489712, 0.004119464469618949], "brevity_penalty": 1.0, "length_ratio": 9.643564356435643, "translation_length": 974, "reference_length": 101}
{"bleu": 2.526051608125611e-11, "precisions": [0.6408934707903781, 0.1153184165232358, 0.03103448275862069, 0.017271157167530225], "brevity_penalty": 3.1840479751432447e-10, "length_ratio": 0.0437298068975881, "translation_length": 582, "reference_length": 13309}
{"bleu": 0.0, "precisions": [0.05828220858895705, 0.0, 0.0, 0.0], "brevity_penalty": 0.7358356651299203, "length_ratio": 0.7652582159624414, "translation_length": 978, "reference_length": 1278}
{"bleu": 0.03477513220851544, "precisions": [0.09572072072072071, 0.02593010146561443, 0.024830699774266364, 0.023728813559322035], "brevity_penalty": 1.0, "length_ratio": 5.584905660377358, "translation_length": 888, "reference_length": 159}
{"error": "Unsloth: input length 161192 + max_new_tokens 1024 exceeds the maximum sequence length of 131072!\nYou will need to do long context extension by increasing the `max_seq_length` in `FastLanguageModel.from_pretrained`."}
{"bleu": 0.007281836103556038, "precisions": [0.376, 0.16316316316316315, 0.13827655310621242, 0.11534603811434303], "brevity_penalty": 0.04117187093906772, "length_ratio": 0.2386634844868735, "translation_length": 1000, "reference_length": 4190}
{"bleu": 0.12299141558830978, "precisions": [0.8842443729903537, 0.832258064516129, 0.8090614886731392, 0.788961038961039], "brevity_penalty": 0.14856207248025305, "length_ratio": 0.3440265486725664, "translation_length": 311, "reference_length": 904}
{"bleu": 0.1095204644585799, "precisions": [0.4208955223880597, 0.2275449101796407, 0.21621621621621623, 0.21385542168674698], "brevity_penalty": 0.42455385349919117, "length_ratio": 0.5385852090032154, "translation_length": 335, "reference_length": 622}
{"bleu": 5.558359204800186e-10, "precisions": [0.6693548387096774, 0.4796747967479675, 0.4426229508196721, 0.4049586776859504], "brevity_penalty": 1.1348399677305291e-09, "length_ratio": 0.04630321135175504, "translation_length": 124, "reference_length": 2678}
{"bleu": 0.0, "precisions": [0.275, 0.07692307692307693, 0.0, 0.0], "brevity_penalty": 0.927743486328553, "length_ratio": 0.9302325581395349, "translation_length": 40, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.1311806256306761, 0.0, 0.0, 0.0], "brevity_penalty": 1.227202578225599e-08, "length_ratio": 0.052040119729034294, "translation_length": 991, "reference_length": 19043}
{"bleu": 0.20368207587936382, "precisions": [0.26153846153846155, 0.1937984496124031, 0.1875, 0.18110236220472442], "brevity_penalty": 1.0, "length_ratio": 1.5116279069767442, "translation_length": 130, "reference_length": 86}
{"bleu": 1.003476919377579e-07, "precisions": [0.2915129151291513, 0.17777777777777778, 0.16356877323420074, 0.14925373134328357], "brevity_penalty": 5.320680379255252e-07, "length_ratio": 0.06473960821786909, "translation_length": 271, "reference_length": 4186}
{"bleu": 0.0, "precisions": [0.014184397163120567, 0.001183431952662722, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 24.88235294117647, "translation_length": 846, "reference_length": 34}
{"bleu": 0.11158790811984559, "precisions": [0.7175, 0.606516290726817, 0.5904522613065326, 0.5869017632241813], "brevity_penalty": 0.17906614791149328, "length_ratio": 0.36764705882352944, "translation_length": 400, "reference_length": 1088}
{"bleu": 0.0, "precisions": [0.012048192771084338, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.608695652173913, "translation_length": 83, "reference_length": 23}
{"bleu": 0.05622808486311756, "precisions": [0.06600985221674877, 0.054240631163708086, 0.05330700888450148, 0.05237154150197629], "brevity_penalty": 1.0, "length_ratio": 8.319672131147541, "translation_length": 1015, "reference_length": 122}
{"bleu": 0.051721045633773825, "precisions": [0.23333333333333334, 0.1397288842544317, 0.13465553235908143, 0.13166144200626959], "brevity_penalty": 0.33356528800084606, "length_ratio": 0.4766633565044687, "translation_length": 960, "reference_length": 2014}
{"bleu": 0.0, "precisions": [0.14893617021276595, 0.0, 0.0, 0.0], "brevity_penalty": 2.931582734097728e-07, "length_ratio": 0.0623342175066313, "translation_length": 47, "reference_length": 754}
{"bleu": 0.07630655266988359, "precisions": [0.0778727445394112, 0.07699619771863118, 0.07611798287345385, 0.07428571428571429], "brevity_penalty": 1.0, "length_ratio": 11.831460674157304, "translation_length": 1053, "reference_length": 89}
{"bleu": 0.0, "precisions": [0.29190056134723336, 0.0898876404494382, 0.04497991967871486, 0.0], "brevity_penalty": 0.6024103874138526, "length_ratio": 0.6636508781266631, "translation_length": 1247, "reference_length": 1879}
{"bleu": 0.3409858981263285, "precisions": [0.8731343283582089, 0.8646616541353384, 0.8560606060606061, 0.8473282442748091], "brevity_penalty": 0.3963834871912119, "length_ratio": 0.5193798449612403, "translation_length": 134, "reference_length": 258}
{"bleu": 0.0, "precisions": [0.009900990099009901, 0.003303964757709251, 0.0011025358324145535, 0.0], "brevity_penalty": 1.0, "length_ratio": 33.666666666666664, "translation_length": 909, "reference_length": 27}
{"bleu": 0.34642848072931204, "precisions": [0.35195530726256985, 0.34831460674157305, 0.3446327683615819, 0.3409090909090909], "brevity_penalty": 1.0, "length_ratio": 2.557142857142857, "translation_length": 179, "reference_length": 70}
{"bleu": 0.0, "precisions": [0.16372549019607843, 0.0, 0.0, 0.0], "brevity_penalty": 0.8760317528329519, "length_ratio": 0.8831168831168831, "translation_length": 1020, "reference_length": 1155}
{"bleu": 0.152315776959082, "precisions": [0.27205882352941174, 0.14814814814814814, 0.12686567164179105, 0.10526315789473684], "brevity_penalty": 1.0, "length_ratio": 1.6790123456790123, "translation_length": 136, "reference_length": 81}
{"bleu": 0.015946328589201423, "precisions": [0.8759036144578313, 0.7551266586248492, 0.7125603864734299, 0.6674727932285369], "brevity_penalty": 0.02129255941866922, "length_ratio": 0.2062111801242236, "translation_length": 830, "reference_length": 4025}
{"bleu": 3.895785320330613e-14, "precisions": [0.7952218430034129, 0.5547945205479452, 0.5154639175257731, 0.5103448275862069], "brevity_penalty": 6.674587087833038e-14, "length_ratio": 0.03191025920278806, "translation_length": 293, "reference_length": 9182}
{"bleu": 0.27457743482540153, "precisions": [0.41368078175895767, 0.2908496732026144, 0.25573770491803277, 0.23355263157894737], "brevity_penalty": 0.9430538228126156, "length_ratio": 0.9446153846153846, "translation_length": 307, "reference_length": 325}
{"bleu": 0.08362379466352252, "precisions": [0.10817031070195628, 0.08294930875576037, 0.07612456747404844, 0.07159353348729793], "brevity_penalty": 1.0, "length_ratio": 6.076923076923077, "translation_length": 869, "reference_length": 143}
{"bleu": 0.011378487351719611, "precisions": [0.09403437815975733, 0.012145748987854251, 0.010131712259371834, 0.008113590263691683], "brevity_penalty": 0.6500291185592153, "length_ratio": 0.6989399293286219, "translation_length": 989, "reference_length": 1415}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 125.85714285714286, "translation_length": 881, "reference_length": 7}
{"bleu": 0.02317391164170999, "precisions": [0.8238557558945908, 0.5305555555555556, 0.5104311543810849, 0.49164345403899723], "brevity_penalty": 0.04026771408441369, "length_ratio": 0.23740533421139282, "translation_length": 721, "reference_length": 3037}
{"bleu": 0.3730217626811023, "precisions": [0.3793103448275862, 0.3751438434982739, 0.3709677419354839, 0.36678200692041524], "brevity_penalty": 1.0, "length_ratio": 2.5588235294117645, "translation_length": 870, "reference_length": 340}
{"bleu": 0.025334766052465207, "precisions": [0.03271028037383177, 0.028169014084507043, 0.02358490566037736, 0.018957345971563982], "brevity_penalty": 1.0, "length_ratio": 15.285714285714286, "translation_length": 214, "reference_length": 14}
