{"bleu": 0.11311803984428015, "precisions": [0.14168377823408623, 0.11316872427983539, 0.10515463917525773, 0.09710743801652892], "brevity_penalty": 1.0, "length_ratio": 5.47191011235955, "translation_length": 487, "reference_length": 89}
{"bleu": 0.09340696065682406, "precisions": [0.12614445574771108, 0.08961303462321792, 0.08460754332313965, 0.07959183673469387], "brevity_penalty": 1.0, "length_ratio": 6.182389937106918, "translation_length": 983, "reference_length": 159}
{"bleu": 0.06560603887112117, "precisions": [0.16293929712460065, 0.060897435897435896, 0.04823151125401929, 0.03870967741935484], "brevity_penalty": 1.0, "length_ratio": 1.95625, "translation_length": 313, "reference_length": 160}
{"bleu": 0.027717652873065712, "precisions": [0.15742574257425743, 0.019821605550049554, 0.015873015873015872, 0.011916583912611719], "brevity_penalty": 1.0, "length_ratio": 2.0159680638722555, "translation_length": 1010, "reference_length": 501}
{"bleu": 0.0, "precisions": [0.00625, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.620938628158845, "translation_length": 1280, "reference_length": 277}
{"bleu": 0.0, "precisions": [0.015444015444015444, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 14.38888888888889, "translation_length": 259, "reference_length": 18}
{"bleu": 0.03359171325304442, "precisions": [0.03501945525291829, 0.034079844206426485, 0.03313840155945419, 0.03219512195121951], "brevity_penalty": 1.0, "length_ratio": 23.906976744186046, "translation_length": 1028, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.025, 0.008368200836820083, 0.004201680672268907, 0.0], "brevity_penalty": 1.0, "length_ratio": 13.333333333333334, "translation_length": 240, "reference_length": 18}
{"bleu": 0.3135650979551922, "precisions": [0.8184818481848185, 0.7847682119205298, 0.7774086378737541, 0.77], "brevity_penalty": 0.39820350741843563, "length_ratio": 0.520618556701031, "translation_length": 303, "reference_length": 582}
{"bleu": 0.000602278404801932, "precisions": [0.35689851767388825, 0.15182648401826485, 0.013714285714285714, 0.006864988558352402], "brevity_penalty": 0.01267275296326486, "length_ratio": 0.1862786745964316, "translation_length": 877, "reference_length": 4708}
{"bleu": 0.018252305219082617, "precisions": [0.02142857142857143, 0.01940755873340143, 0.017382413087934562, 0.015353121801432957], "brevity_penalty": 1.0, "length_ratio": 33.793103448275865, "translation_length": 980, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.014736842105263158, 0.002107481559536354, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 32.758620689655174, "translation_length": 950, "reference_length": 29}
{"bleu": 0.0, "precisions": [0.2857142857142857, 0.04838709677419355, 0.01639344262295082, 0.0], "brevity_penalty": 0.005934431002839445, "length_ratio": 0.16321243523316062, "translation_length": 63, "reference_length": 386}
{"bleu": 0.0, "precisions": [0.03680336487907466, 0.01263157894736842, 0.006322444678609062, 0.0], "brevity_penalty": 1.0, "length_ratio": 12.68, "translation_length": 951, "reference_length": 75}
{"bleu": 0.0, "precisions": [0.005917159763313609, 0.0019743336623889436, 0.0009881422924901185, 0.0], "brevity_penalty": 1.0, "length_ratio": 59.64705882352941, "translation_length": 1014, "reference_length": 17}
{"bleu": 0.0, "precisions": [0.08823529411764706, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.096774193548387, "translation_length": 68, "reference_length": 62}
{"bleu": 0.0, "precisions": [0.08527131782945736, 0.0078125, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.5925925925925926, "translation_length": 129, "reference_length": 81}
{"bleu": 0.0, "precisions": [0.06666666666666667, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.1951219512195124, "translation_length": 90, "reference_length": 41}
{"bleu": 0.12446603279124052, "precisions": [0.5725190839694656, 0.36923076923076925, 0.3333333333333333, 0.3125], "brevity_penalty": 0.32310724197518115, "length_ratio": 0.46953405017921146, "translation_length": 131, "reference_length": 279}
{"bleu": 0.0, "precisions": [0.03297872340425532, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 5.949367088607595, "translation_length": 940, "reference_length": 158}
{"bleu": 0.04536080763510752, "precisions": [0.05361930294906166, 0.04838709677419355, 0.0431266846361186, 0.03783783783783784], "brevity_penalty": 1.0, "length_ratio": 17.761904761904763, "translation_length": 373, "reference_length": 21}
{"bleu": 0.06402462834683882, "precisions": [0.06779661016949153, 0.06361323155216285, 0.06281833616298811, 0.062022090059473234], "brevity_penalty": 1.0, "length_ratio": 14.216867469879517, "translation_length": 1180, "reference_length": 83}
{"bleu": 2.2892942954130576e-13, "precisions": [0.5172413793103449, 0.2807017543859649, 0.23214285714285715, 0.14545454545454545], "brevity_penalty": 8.651598832207672e-13, "length_ratio": 0.0347513481126423, "translation_length": 58, "reference_length": 1669}
{"bleu": 1.3788100181575288e-34, "precisions": [0.4883720930232558, 0.15625, 0.11811023622047244, 0.09523809523809523], "brevity_penalty": 8.055400807211714e-34, "length_ratio": 0.01295310774174114, "translation_length": 129, "reference_length": 9959}
{"bleu": 0.024100896613018927, "precisions": [0.28361581920903955, 0.014705882352941176, 0.010192525481313703, 0.007936507936507936], "brevity_penalty": 1.0, "length_ratio": 1.1629434954007885, "translation_length": 885, "reference_length": 761}
{"error": "CUDA out of memory. Tried to allocate 352.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 196.69 MiB is free. Including non-PyTorch memory, this process has 10.55 GiB memory in use. Of the allocated memory 10.06 GiB is allocated by PyTorch, and 294.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.028350491335947334, "precisions": [0.02982107355864811, 0.028855721393034824, 0.027888446215139442, 0.026919242273180457], "brevity_penalty": 1.0, "length_ratio": 27.18918918918919, "translation_length": 1006, "reference_length": 37}
{"bleu": 0.02033739156538269, "precisions": [0.028484231943031537, 0.021384928716904276, 0.01834862385321101, 0.015306122448979591], "brevity_penalty": 1.0, "length_ratio": 31.70967741935484, "translation_length": 983, "reference_length": 31}
{"bleu": 9.214629371701072e-06, "precisions": [0.9409547738693468, 0.9270440251572327, 0.9269521410579346, 0.926860025220681], "brevity_penalty": 9.903591732806372e-06, "length_ratio": 0.07985553772070626, "translation_length": 796, "reference_length": 9968}
{"bleu": 0.0, "precisions": [0.0061162079510703364, 0.0020408163265306124, 0.0010214504596527069, 0.0], "brevity_penalty": 1.0, "length_ratio": 54.5, "translation_length": 981, "reference_length": 18}
{"bleu": 0.020210533053470203, "precisions": [0.06578947368421052, 0.017223910840932118, 0.013184584178498986, 0.01116751269035533], "brevity_penalty": 1.0, "length_ratio": 6.415584415584416, "translation_length": 988, "reference_length": 154}
{"bleu": 0.04519024450344928, "precisions": [0.5125, 0.4050632911392405, 0.3974358974358974, 0.38961038961038963], "brevity_penalty": 0.10672498360043615, "length_ratio": 0.3088803088803089, "translation_length": 80, "reference_length": 259}
{"bleu": 0.051024487200436425, "precisions": [0.37254901960784315, 0.2204724409448819, 0.16205533596837945, 0.10714285714285714], "brevity_penalty": 0.2625654480923914, "length_ratio": 0.4278523489932886, "translation_length": 255, "reference_length": 596}
{"bleu": 0.05783696262572227, "precisions": [0.1111111111111111, 0.064, 0.04838709677419355, 0.032520325203252036], "brevity_penalty": 1.0, "length_ratio": 3.073170731707317, "translation_length": 126, "reference_length": 41}
{"bleu": 0.6232299142379445, "precisions": [0.8173913043478261, 0.7894736842105263, 0.7787610619469026, 0.7678571428571429], "brevity_penalty": 0.7907427315390552, "length_ratio": 0.8098591549295775, "translation_length": 115, "reference_length": 142}
{"error": "CUDA out of memory. Tried to allocate 272.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 140.69 MiB is free. Including non-PyTorch memory, this process has 10.61 GiB memory in use. Of the allocated memory 10.09 GiB is allocated by PyTorch, and 312.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.011764705882352941, 0.0029455081001472753, 0.0014749262536873156, 0.0], "brevity_penalty": 1.0, "length_ratio": 37.77777777777778, "translation_length": 680, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.1348314606741573, 0.0, 0.0, 0.0], "brevity_penalty": 0.06483205926789484, "length_ratio": 0.26766917293233083, "translation_length": 178, "reference_length": 665}
{"bleu": 0.2131270228258432, "precisions": [0.30201342281879195, 0.20945945945945946, 0.19047619047619047, 0.17123287671232876], "brevity_penalty": 1.0, "length_ratio": 1.3925233644859814, "translation_length": 149, "reference_length": 107}
{"bleu": 4.831256821281992e-15, "precisions": [0.7052631578947368, 0.5212765957446809, 0.4946236559139785, 0.4673913043478261], "brevity_penalty": 8.947802521878685e-15, "length_ratio": 0.029987373737373736, "translation_length": 95, "reference_length": 3168}
{"bleu": 0.2860849205298861, "precisions": [0.3681528662420382, 0.2844387755102041, 0.26053639846743293, 0.24552429667519182], "brevity_penalty": 1.0, "length_ratio": 1.6020408163265305, "translation_length": 785, "reference_length": 490}
{"bleu": 0.24150929686924488, "precisions": [0.3607103218645949, 0.25, 0.20912124582869857, 0.18040089086859687], "brevity_penalty": 1.0, "length_ratio": 1.8692946058091287, "translation_length": 901, "reference_length": 482}
{"bleu": 0.04163096749850134, "precisions": [0.15920915712799166, 0.03333333333333333, 0.027111574556830033, 0.020876826722338204], "brevity_penalty": 1.0, "length_ratio": 1.318244170096022, "translation_length": 961, "reference_length": 729}
{"bleu": 0.0, "precisions": [0.09243697478991597, 0.004219409282700422, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.7246376811594204, "translation_length": 238, "reference_length": 138}
{"bleu": 0.08324526000289541, "precisions": [0.1076581576026637, 0.08555555555555555, 0.07675194660734148, 0.06792873051224944], "brevity_penalty": 1.0, "length_ratio": 5.738853503184713, "translation_length": 901, "reference_length": 157}
{"bleu": 0.0, "precisions": [0.005172413793103448, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 20.350877192982455, "translation_length": 1160, "reference_length": 57}
{"bleu": 0.024493514074007714, "precisions": [0.05637982195845697, 0.023809523809523808, 0.01791044776119403, 0.014970059880239521], "brevity_penalty": 1.0, "length_ratio": 9.911764705882353, "translation_length": 337, "reference_length": 34}
{"bleu": 0.7023613859782101, "precisions": [0.9954001839926403, 0.9935543278084714, 0.9907834101382489, 0.9907749077490775], "brevity_penalty": 0.7075788805376857, "length_ratio": 0.7429938482570062, "translation_length": 1087, "reference_length": 1463}
{"bleu": 5.283078537986422e-07, "precisions": [0.476, 0.30120481927710846, 0.2903225806451613, 0.2793522267206478], "brevity_penalty": 1.6088353915567235e-06, "length_ratio": 0.0697350069735007, "translation_length": 250, "reference_length": 3585}
{"bleu": 0.0, "precisions": [0.33653846153846156, 0.04854368932038835, 0.0196078431372549, 0.0], "brevity_penalty": 8.672717043841027e-27, "length_ratio": 0.016390858944050433, "translation_length": 104, "reference_length": 6345}
{"bleu": 0.06490102064861127, "precisions": [0.256353591160221, 0.05752212389380531, 0.03875968992248062, 0.031042128603104215], "brevity_penalty": 1.0, "length_ratio": 1.3923076923076922, "translation_length": 905, "reference_length": 650}
{"bleu": 0.0, "precisions": [0.2879581151832461, 0.031578947368421054, 0.0, 0.0], "brevity_penalty": 0.31440665139095303, "length_ratio": 0.46359223300970875, "translation_length": 191, "reference_length": 412}
{"bleu": 0.11428864539536833, "precisions": [0.9774436090225563, 0.9560853199498118, 0.9434673366834171, 0.9333333333333333], "brevity_penalty": 0.11999553420154639, "length_ratio": 0.3204819277108434, "translation_length": 798, "reference_length": 2490}
{"bleu": 0.030089516795522818, "precisions": [0.03474320241691843, 0.03177004538577912, 0.02878787878787879, 0.025796661608497723], "brevity_penalty": 1.0, "length_ratio": 22.066666666666666, "translation_length": 662, "reference_length": 30}
{"bleu": 0.0008472407344260575, "precisions": [0.9953917050691244, 0.9907727797001153, 0.9884526558891455, 0.9849710982658959], "brevity_penalty": 0.0008558939708709159, "length_ratio": 0.12401771681668809, "translation_length": 868, "reference_length": 6999}
{"error": "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 116.69 MiB is free. Including non-PyTorch memory, this process has 10.63 GiB memory in use. Of the allocated memory 9.89 GiB is allocated by PyTorch, and 541.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 16.69 MiB is free. Including non-PyTorch memory, this process has 10.73 GiB memory in use. Of the allocated memory 9.99 GiB is allocated by PyTorch, and 539.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.21875, 0.010471204188481676, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.1428571428571428, "translation_length": 192, "reference_length": 168}
{"bleu": 0.0, "precisions": [0.1619718309859155, 0.0070921985815602835, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.5604395604395604, "translation_length": 142, "reference_length": 91}
{"bleu": 0.0, "precisions": [0.19540229885057472, 0.046242774566473986, 0.023255813953488372, 0.0], "brevity_penalty": 0.021267510218410016, "length_ratio": 0.20616113744075829, "translation_length": 174, "reference_length": 844}
{"bleu": 0.0, "precisions": [0.03902439024390244, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.3076923076923075, "translation_length": 410, "reference_length": 65}
{"bleu": 0.0, "precisions": [0.007223942208462332, 0.0010330578512396695, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 40.375, "translation_length": 969, "reference_length": 24}
{"bleu": 0.0, "precisions": [0.04639175257731959, 0.0051813471502590676, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 4.041666666666667, "translation_length": 194, "reference_length": 48}
{"bleu": 0.0, "precisions": [0.11764705882352941, 0.0, 0.0, 0.0], "brevity_penalty": 4.6963952610398475e-09, "length_ratio": 0.04956268221574344, "translation_length": 17, "reference_length": 343}
{"bleu": 0.0, "precisions": [0.16837782340862423, 0.011305241521068859, 0.0051440329218107, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.0668127053669223, "translation_length": 974, "reference_length": 913}
{"bleu": 1.445093580249698e-28, "precisions": [0.640625, 0.49206349206349204, 0.46774193548387094, 0.4426229508196721], "brevity_penalty": 2.8591020409407206e-28, "length_ratio": 0.015522677661896677, "translation_length": 64, "reference_length": 4123}
{"bleu": 0.03293577614922197, "precisions": [0.06502242152466367, 0.04044943820224719, 0.024774774774774775, 0.01805869074492099], "brevity_penalty": 1.0, "length_ratio": 9.911111111111111, "translation_length": 446, "reference_length": 45}
{"bleu": 0.12671265443459442, "precisions": [0.2242798353909465, 0.12461380020597322, 0.10515463917525773, 0.08771929824561403], "brevity_penalty": 1.0, "length_ratio": 2.370731707317073, "translation_length": 972, "reference_length": 410}
{"bleu": 0.24344802144722846, "precisions": [0.2465753424657534, 0.2445054945054945, 0.24242424242424243, 0.24033149171270718], "brevity_penalty": 1.0, "length_ratio": 3.7628865979381443, "translation_length": 365, "reference_length": 97}
{"bleu": 0.09849360547040086, "precisions": [0.53125, 0.19603753910323254, 0.15866388308977036, 0.12748171368861025], "brevity_penalty": 0.45974498055247137, "length_ratio": 0.5627198124267292, "translation_length": 960, "reference_length": 1706}
{"bleu": 1.2370286295338279e-05, "precisions": [0.6503623188405797, 0.41197822141560797, 0.32, 0.2641165755919854], "brevity_penalty": 3.1888635372453635e-05, "length_ratio": 0.0880804212541886, "translation_length": 552, "reference_length": 6267}
{"bleu": 0.07001980770478816, "precisions": [0.21701199563794984, 0.12554585152838427, 0.12131147540983607, 0.11706783369803063], "brevity_penalty": 0.4992459152214051, "length_ratio": 0.5900900900900901, "translation_length": 917, "reference_length": 1554}
{"bleu": 0.0, "precisions": [0.04851157662624035, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.572463768115942, "translation_length": 907, "reference_length": 138}
{"bleu": 0.0, "precisions": [0.12645161290322582, 0.00516795865633075, 0.00258732212160414, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.491961414790997, "translation_length": 775, "reference_length": 311}
{"bleu": 1.8175189706400384e-08, "precisions": [0.13211600429645542, 0.007526881720430108, 0.0032292787944025836, 0.0010775862068965517], "brevity_penalty": 2.369719438195526e-06, "length_ratio": 0.07167051578137028, "translation_length": 931, "reference_length": 12990}
{"bleu": 0.0, "precisions": [0.07766990291262135, 0.00980392156862745, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.019607843137255, "translation_length": 103, "reference_length": 51}
{"bleu": 0.00765350790293419, "precisions": [0.010428736964078795, 0.008120649651972157, 0.006968641114982578, 0.005813953488372093], "brevity_penalty": 1.0, "length_ratio": 41.095238095238095, "translation_length": 863, "reference_length": 21}
{"bleu": 0.0, "precisions": [0.22340425531914893, 0.0, 0.0, 0.0], "brevity_penalty": 1.3023769012501397e-38, "length_ratio": 0.011333494092114782, "translation_length": 94, "reference_length": 8294}
{"error": "CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 118.69 MiB is free. Including non-PyTorch memory, this process has 10.63 GiB memory in use. Of the allocated memory 9.94 GiB is allocated by PyTorch, and 495.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.012108530429949594, "precisions": [0.025, 0.01251303441084463, 0.009394572025052192, 0.0073145245559038665], "brevity_penalty": 1.0, "length_ratio": 16.271186440677965, "translation_length": 960, "reference_length": 59}
{"bleu": 2.2434029063604256e-26, "precisions": [0.5546875, 0.31496062992125984, 0.2857142857142857, 0.272], "brevity_penalty": 6.572126299741921e-26, "length_ratio": 0.01695364238410596, "translation_length": 128, "reference_length": 7550}
{"bleu": 0.3597538363857189, "precisions": [0.5336405529953917, 0.45940959409594095, 0.4293628808864266, 0.3955637707948244], "brevity_penalty": 0.7964031355977021, "length_ratio": 0.8145645645645646, "translation_length": 1085, "reference_length": 1332}
{"bleu": 0.00623144976581266, "precisions": [0.03825136612021858, 0.005470459518599562, 0.0032858707557502738, 0.0021929824561403508], "brevity_penalty": 1.0, "length_ratio": 7.56198347107438, "translation_length": 915, "reference_length": 121}
{"bleu": 7.701196564096848e-05, "precisions": [0.4952581664910432, 0.3048523206751055, 0.27983104540654696, 0.27906976744186046], "brevity_penalty": 0.00023370916798753702, "length_ratio": 0.10682125168842864, "translation_length": 949, "reference_length": 8884}
{"bleu": 0.11550159617418193, "precisions": [0.22778345250255363, 0.09406952965235174, 0.09211873080859775, 0.09016393442622951], "brevity_penalty": 1.0, "length_ratio": 1.7327433628318585, "translation_length": 979, "reference_length": 565}
{"bleu": 0.37563555880944566, "precisions": [0.3766968325791855, 0.37599093997734995, 0.37528344671201813, 0.3745743473325766], "brevity_penalty": 1.0, "length_ratio": 2.6, "translation_length": 884, "reference_length": 340}
{"bleu": 1.1653887874028365e-17, "precisions": [0.7972027972027972, 0.7605633802816901, 0.7588652482269503, 0.7571428571428571], "brevity_penalty": 1.5169076983030537e-17, "length_ratio": 0.02517162471395881, "translation_length": 143, "reference_length": 5681}
{"bleu": 0.0, "precisions": [0.03571428571428571, 0.0, 0.0, 0.0], "brevity_penalty": 0.9823013510997375, "length_ratio": 0.9824561403508771, "translation_length": 56, "reference_length": 57}
{"bleu": 0.6079804224371731, "precisions": [0.76010101010101, 0.6936708860759494, 0.649746192893401, 0.6157760814249363], "brevity_penalty": 0.8971018676125706, "length_ratio": 0.9020501138952164, "translation_length": 396, "reference_length": 439}
{"bleu": 0.08338276213197018, "precisions": [0.2644628099173554, 0.09166666666666666, 0.058823529411764705, 0.03389830508474576], "brevity_penalty": 1.0, "length_ratio": 1.0521739130434782, "translation_length": 121, "reference_length": 115}
{"bleu": 0.02707528024770272, "precisions": [0.125, 0.032388663967611336, 0.016260162601626018, 0.00816326530612245], "brevity_penalty": 1.0, "length_ratio": 4.0, "translation_length": 248, "reference_length": 62}
{"bleu": 0.08391040042355637, "precisions": [0.17519685039370078, 0.07684729064039408, 0.06903353057199212, 0.0631786771964462], "brevity_penalty": 0.9585602741490169, "length_ratio": 0.959395656279509, "translation_length": 1016, "reference_length": 1059}
{"bleu": 0.0, "precisions": [0.10576015108593012, 0.0, 0.0, 0.0], "brevity_penalty": 0.558430494776379, "length_ratio": 0.6318615751789977, "translation_length": 1059, "reference_length": 1676}
{"bleu": 0.004911476467352551, "precisions": [0.481941309255079, 0.25084745762711863, 0.20361990950226244, 0.16761041902604756], "brevity_penalty": 0.019378974458803017, "length_ratio": 0.20228310502283106, "translation_length": 886, "reference_length": 4380}
{"bleu": 0.44294558556233926, "precisions": [0.9234449760765551, 0.9016786570743405, 0.8942307692307693, 0.8867469879518072], "brevity_penalty": 0.4913855054398576, "length_ratio": 0.5846153846153846, "translation_length": 418, "reference_length": 715}
{"bleu": 6.857669826281316e-08, "precisions": [0.5701754385964912, 0.4336283185840708, 0.42857142857142855, 0.42342342342342343], "brevity_penalty": 1.4900317155640455e-07, "length_ratio": 0.05981112277019937, "translation_length": 114, "reference_length": 1906}
{"bleu": 0.3528599487315663, "precisions": [0.42963752665245203, 0.35965848452508004, 0.327991452991453, 0.3058823529411765], "brevity_penalty": 1.0, "length_ratio": 1.9623430962343096, "translation_length": 938, "reference_length": 478}
{"bleu": 0.16028178405668644, "precisions": [0.6139380530973452, 0.39313399778516056, 0.38470066518847007, 0.3762486126526082], "brevity_penalty": 0.37073912264966713, "length_ratio": 0.5019433647973348, "translation_length": 904, "reference_length": 1801}
{"bleu": 0.0, "precisions": [0.17613636363636365, 0.0, 0.0, 0.0], "brevity_penalty": 0.15777411684443315, "length_ratio": 0.35129740518962077, "translation_length": 176, "reference_length": 501}
{"bleu": 0.009886249480683581, "precisions": [0.31, 0.17017017017017017, 0.15831663326653306, 0.1464393179538616], "brevity_penalty": 0.05286572873835034, "length_ratio": 0.25380710659898476, "translation_length": 1000, "reference_length": 3940}
{"bleu": 0.17471407732693492, "precisions": [0.18565400843881857, 0.17529039070749736, 0.17124735729386892, 0.1671957671957672], "brevity_penalty": 1.0, "length_ratio": 3.2354948805460753, "translation_length": 948, "reference_length": 293}
{"bleu": 0.044492003194804564, "precisions": [0.06481481481481481, 0.056074766355140186, 0.03773584905660377, 0.02857142857142857], "brevity_penalty": 1.0, "length_ratio": 15.428571428571429, "translation_length": 108, "reference_length": 7}
{"bleu": 0.10818943277614262, "precisions": [0.5108853410740203, 0.17005813953488372, 0.1586608442503639, 0.14868804664723032], "brevity_penalty": 0.5084733238207467, "length_ratio": 0.5965367965367966, "translation_length": 689, "reference_length": 1155}
{"bleu": 0.03526315115126715, "precisions": [0.04133858267716536, 0.03645320197044335, 0.03353057199211045, 0.03060217176702863], "brevity_penalty": 1.0, "length_ratio": 23.627906976744185, "translation_length": 1016, "reference_length": 43}
{"bleu": 0.04321409190691044, "precisions": [0.046460176991150445, 0.04434589800443459, 0.042222222222222223, 0.0400890868596882], "brevity_penalty": 1.0, "length_ratio": 16.142857142857142, "translation_length": 452, "reference_length": 28}
{"bleu": 0.06834271194032437, "precisions": [0.0783132530120482, 0.06934673366834171, 0.06539235412474849, 0.06143001007049345], "brevity_penalty": 1.0, "length_ratio": 12.0, "translation_length": 996, "reference_length": 83}
{"bleu": 0.008789768246383408, "precisions": [0.01346389228886169, 0.00980392156862745, 0.007361963190184049, 0.006142506142506142], "brevity_penalty": 1.0, "length_ratio": 38.904761904761905, "translation_length": 817, "reference_length": 21}
{"error": "CUDA out of memory. Tried to allocate 252.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 198.69 MiB is free. Including non-PyTorch memory, this process has 10.55 GiB memory in use. Of the allocated memory 10.02 GiB is allocated by PyTorch, and 326.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.02214022140221402, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 11.291666666666666, "translation_length": 271, "reference_length": 24}
{"error": "CUDA out of memory. Tried to allocate 392.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 136.69 MiB is free. Including non-PyTorch memory, this process has 10.61 GiB memory in use. Of the allocated memory 9.96 GiB is allocated by PyTorch, and 453.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.061224489795918366, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.9696969696969697, "translation_length": 98, "reference_length": 33}
{"bleu": 0.04982856300360744, "precisions": [0.1625, 0.0759493670886076, 0.038461538461538464, 0.012987012987012988], "brevity_penalty": 1.0, "length_ratio": 1.4035087719298245, "translation_length": 80, "reference_length": 57}
{"bleu": 0.021941827541923205, "precisions": [0.09316770186335403, 0.03125, 0.012578616352201259, 0.006329113924050633], "brevity_penalty": 1.0, "length_ratio": 2.824561403508772, "translation_length": 161, "reference_length": 57}
{"bleu": 0.7151891489909705, "precisions": [0.7371349095966621, 0.7144846796657381, 0.7071129707112971, 0.702513966480447], "brevity_penalty": 1.0, "length_ratio": 1.274822695035461, "translation_length": 719, "reference_length": 564}
{"bleu": 9.553779701422803e-05, "precisions": [0.32628398791540786, 0.02620967741935484, 0.01917255297679112, 0.012121212121212121], "brevity_penalty": 0.002544511182888979, "length_ratio": 0.14339350180505414, "translation_length": 993, "reference_length": 6925}
{"bleu": 0.24719983617595281, "precisions": [0.3349705304518664, 0.22812192723697147, 0.2234251968503937, 0.2187192118226601], "brevity_penalty": 1.0, "length_ratio": 1.0059288537549407, "translation_length": 1018, "reference_length": 1012}
{"bleu": 0.0, "precisions": [0.059907834101382486, 0.0011534025374855825, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.382352941176471, "translation_length": 868, "reference_length": 136}
{"bleu": 0.6133693554689709, "precisions": [0.6308243727598566, 0.6151079136690647, 0.6064981949458483, 0.6014492753623188], "brevity_penalty": 1.0, "length_ratio": 1.4840425531914894, "translation_length": 279, "reference_length": 188}
{"bleu": 0.14393574417005825, "precisions": [0.5125260960334029, 0.367816091954023, 0.33158995815899583, 0.3068062827225131], "brevity_penalty": 0.3867813951882142, "length_ratio": 0.512847965738758, "translation_length": 958, "reference_length": 1868}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 150.0, "translation_length": 1050, "reference_length": 7}
{"bleu": 0.190758615875078, "precisions": [0.4105263157894737, 0.16415662650602408, 0.1478129713423831, 0.13293051359516617], "brevity_penalty": 1.0, "length_ratio": 1.2269372693726937, "translation_length": 665, "reference_length": 542}
{"bleu": 1.950478174951918e-06, "precisions": [0.6307692307692307, 0.34375, 0.31746031746031744, 0.2903225806451613], "brevity_penalty": 5.187644749748543e-06, "length_ratio": 0.07593457943925233, "translation_length": 65, "reference_length": 856}
{"bleu": 0.0, "precisions": [0.02850877192982456, 0.0043907793633369925, 0.002197802197802198, 0.0], "brevity_penalty": 1.0, "length_ratio": 16.285714285714285, "translation_length": 912, "reference_length": 56}
{"bleu": 0.004911513557987984, "precisions": [0.95, 0.9372384937238494, 0.9327731092436975, 0.9240506329113924], "brevity_penalty": 0.005247518399181385, "length_ratio": 0.16, "translation_length": 240, "reference_length": 1500}
{"bleu": 0.01956957980403829, "precisions": [0.45601851851851855, 0.30243337195828507, 0.28306264501160094, 0.2694541231126597], "brevity_penalty": 0.06110638674502714, "length_ratio": 0.26349496797804206, "translation_length": 864, "reference_length": 3279}
{"bleu": 0.00839518182185369, "precisions": [0.673469387755102, 0.5833333333333334, 0.574468085106383, 0.5652173913043478], "brevity_penalty": 0.014047566199406284, "length_ratio": 0.18992248062015504, "translation_length": 49, "reference_length": 258}
{"bleu": 0.04897352286232406, "precisions": [0.051457975986277875, 0.04982817869415808, 0.04819277108433735, 0.04655172413793104], "brevity_penalty": 1.0, "length_ratio": 15.756756756756756, "translation_length": 583, "reference_length": 37}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 6.333333333333333, "translation_length": 57, "reference_length": 9}
