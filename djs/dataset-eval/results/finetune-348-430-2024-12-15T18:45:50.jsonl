{"bleu": 0.0, "precisions": [0.030162412993039442, 0.0069767441860465115, 0.002331002331002331, 0.0], "brevity_penalty": 0.06516332497618357, "length_ratio": 0.26803482587064675, "translation_length": 431, "reference_length": 1608}
{"bleu": 0.0, "precisions": [0.0004878048780487805, 0.0, 0.0, 0.0], "brevity_penalty": 0.01249484619130736, "length_ratio": 0.18578937828529998, "translation_length": 2050, "reference_length": 11034}
{"bleu": 0.05288260367202347, "precisions": [0.06239015817223199, 0.05452946350043975, 0.05017605633802817, 0.04581497797356828], "brevity_penalty": 1.0, "length_ratio": 14.049382716049383, "translation_length": 1138, "reference_length": 81}
{"bleu": 0.12834388104585512, "precisions": [0.27608346709470305, 0.13815261044176708, 0.10048231511254019, 0.07079646017699115], "brevity_penalty": 1.0, "length_ratio": 1.3499458288190682, "translation_length": 1246, "reference_length": 923}
{"bleu": 0.03109089693639789, "precisions": [0.4078341013824885, 0.17301038062283736, 0.1558891454965358, 0.14566473988439307], "brevity_penalty": 0.1554002624669145, "length_ratio": 0.3494363929146538, "translation_length": 868, "reference_length": 2484}
{"bleu": 0.6590904830993239, "precisions": [0.9840881272949816, 0.9767156862745098, 0.9705521472392638, 0.9643734643734644], "brevity_penalty": 0.6767503208545177, "length_ratio": 0.7191901408450704, "translation_length": 817, "reference_length": 1136}
{"bleu": 0.0, "precisions": [0.0851063829787234, 0.0, 0.0, 0.0], "brevity_penalty": 0.39212672523825076, "length_ratio": 0.5164835164835165, "translation_length": 47, "reference_length": 91}
{"bleu": 0.08659831652663039, "precisions": [0.09182736455463728, 0.08731617647058823, 0.08463661453541858, 0.08287292817679558], "brevity_penalty": 1.0, "length_ratio": 9.81081081081081, "translation_length": 1089, "reference_length": 111}
{"bleu": 0.0, "precisions": [0.0031620553359683794, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 52.708333333333336, "translation_length": 1265, "reference_length": 24}
{"bleu": 0.0, "precisions": [0.01485148514851485, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 25.25, "translation_length": 1010, "reference_length": 40}
{"bleu": 0.0, "precisions": [0.2361863488624052, 0.019522776572668113, 0.0054288816503800215, 0.0], "brevity_penalty": 0.0008452825115367129, "length_ratio": 0.12382613361953314, "translation_length": 923, "reference_length": 7454}
{"bleu": 1.4613982793299654e-05, "precisions": [0.5864661654135338, 0.38924731182795697, 0.2917115177610334, 0.2435344827586207], "brevity_penalty": 4.0951794365224324e-05, "length_ratio": 0.09006481571055432, "translation_length": 931, "reference_length": 10337}
{"bleu": 0.0, "precisions": [0.25, 0.0, 0.0, 0.0], "brevity_penalty": 2.1445408316589164e-05, "length_ratio": 0.0851063829787234, "translation_length": 8, "reference_length": 94}
{"error": "CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 94.69 MiB is free. Including non-PyTorch memory, this process has 10.65 GiB memory in use. Of the allocated memory 10.28 GiB is allocated by PyTorch, and 164.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 54.69 MiB is free. Including non-PyTorch memory, this process has 10.69 GiB memory in use. Of the allocated memory 10.34 GiB is allocated by PyTorch, and 147.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.1, 0.0, 0.0, 0.0], "brevity_penalty": 0.0022428677194858034, "length_ratio": 0.14084507042253522, "translation_length": 10, "reference_length": 71}
{"bleu": 0.0, "precisions": [0.058823529411764705, 0.0, 0.0, 0.0], "brevity_penalty": 0.7903383629814982, "length_ratio": 0.8095238095238095, "translation_length": 17, "reference_length": 21}
{"bleu": 0.29137947355439525, "precisions": [0.4877450980392157, 0.30920245398773005, 0.3046683046683047, 0.3025830258302583], "brevity_penalty": 0.8485589796160492, "length_ratio": 0.8589473684210527, "translation_length": 816, "reference_length": 950}
{"bleu": 0.015443889272608036, "precisions": [0.958904109589041, 0.9027777777777778, 0.9014084507042254, 0.9], "brevity_penalty": 0.01687044877500055, "length_ratio": 0.1967654986522911, "translation_length": 73, "reference_length": 371}
{"bleu": 0.025469221889512183, "precisions": [0.42528735632183906, 0.0741687979539642, 0.04737516005121639, 0.04358974358974359], "brevity_penalty": 0.283501915714318, "length_ratio": 0.4423728813559322, "translation_length": 783, "reference_length": 1770}
{"bleu": 0.22018770764696785, "precisions": [0.4948921679909194, 0.34204545454545454, 0.31285551763367464, 0.28815489749430523], "brevity_penalty": 0.6264725018709117, "length_ratio": 0.6813611755607115, "translation_length": 881, "reference_length": 1293}
{"bleu": 0.0, "precisions": [0.07692307692307693, 0.0, 0.0, 0.0], "brevity_penalty": 0.09949058049485841, "length_ratio": 0.3023255813953488, "translation_length": 13, "reference_length": 43}
{"bleu": 0.0047639003648121975, "precisions": [0.9375639713408394, 0.8975409836065574, 0.8646153846153846, 0.8316221765913757], "brevity_penalty": 0.005401465604797546, "length_ratio": 0.16074366567949983, "translation_length": 977, "reference_length": 6078}
{"bleu": 0.07277668016463382, "precisions": [0.1357615894039735, 0.07845303867403315, 0.05530973451327434, 0.047619047619047616], "brevity_penalty": 1.0, "length_ratio": 4.253521126760563, "translation_length": 906, "reference_length": 213}
{"bleu": 0.0, "precisions": [0.2, 0.0, 0.0, 0.0], "brevity_penalty": 0.740818220681718, "length_ratio": 0.7692307692307693, "translation_length": 10, "reference_length": 13}
{"bleu": 0.0, "precisions": [0.0004992511233150275, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 14.514492753623188, "translation_length": 2003, "reference_length": 138}
{"bleu": 0.0, "precisions": [0.11764705882352941, 0.0, 0.0, 0.0], "brevity_penalty": 0.6624801353939264, "length_ratio": 0.7083333333333334, "translation_length": 17, "reference_length": 24}
{"bleu": 0.0, "precisions": [0.006986027944111776, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 21.782608695652176, "translation_length": 1002, "reference_length": 46}
{"bleu": 0.01311134086920541, "precisions": [0.07049345417925479, 0.017137096774193547, 0.006054490413723511, 0.00404040404040404], "brevity_penalty": 1.0, "length_ratio": 3.650735294117647, "translation_length": 993, "reference_length": 272}
{"bleu": 0.13069274005205833, "precisions": [0.7105978260869565, 0.5591836734693878, 0.4659400544959128, 0.39836289222373805], "brevity_penalty": 0.2507867822629451, "length_ratio": 0.41961231470923605, "translation_length": 736, "reference_length": 1754}
{"bleu": 0.0, "precisions": [0.010089686098654708, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 29.733333333333334, "translation_length": 892, "reference_length": 30}
{"bleu": 0.0, "precisions": [0.01639344262295082, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 7.176470588235294, "translation_length": 732, "reference_length": 102}
{"error": "CUDA out of memory. Tried to allocate 504.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 272.69 MiB is free. Including non-PyTorch memory, this process has 10.48 GiB memory in use. Of the allocated memory 10.10 GiB is allocated by PyTorch, and 171.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.024390243902439025, 0.0048828125, 0.0009775171065493646, 0.0], "brevity_penalty": 1.0, "length_ratio": 13.85135135135135, "translation_length": 1025, "reference_length": 74}
{"bleu": 0.006617321137271146, "precisions": [0.013902681231380337, 0.006958250497017893, 0.004975124378109453, 0.00398406374501992], "brevity_penalty": 1.0, "length_ratio": 28.771428571428572, "translation_length": 1007, "reference_length": 35}
{"bleu": 0.0, "precisions": [0.15789473684210525, 0.0, 0.0, 0.0], "brevity_penalty": 0.5907775139012316, "length_ratio": 0.6551724137931034, "translation_length": 19, "reference_length": 29}
{"bleu": 0.3954560944724798, "precisions": [0.4309623430962343, 0.4036312849162011, 0.38461538461538464, 0.36554621848739494], "brevity_penalty": 1.0, "length_ratio": 1.8968253968253967, "translation_length": 717, "reference_length": 378}
{"bleu": 0.0, "precisions": [0.2, 0.0, 0.0, 0.0], "brevity_penalty": 0.04735892439114093, "length_ratio": 0.24691358024691357, "translation_length": 20, "reference_length": 81}
{"bleu": 0.0, "precisions": [0.10638297872340426, 0.0, 0.0, 0.0], "brevity_penalty": 0.9381646735450738, "length_ratio": 0.94, "translation_length": 47, "reference_length": 50}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 0.6703200460356393, "length_ratio": 0.7142857142857143, "translation_length": 10, "reference_length": 14}
{"bleu": 2.8579766638709842e-06, "precisions": [0.5781563126252505, 0.12637913741223672, 0.0783132530120482, 0.06432160804020101], "brevity_penalty": 2.0633859750713805e-05, "length_ratio": 0.08482787930301743, "translation_length": 998, "reference_length": 11765}
{"bleu": 0.0, "precisions": [0.25, 0.0, 0.0, 0.0], "brevity_penalty": 9.693298441056218e-105, "length_ratio": 0.004158004158004158, "translation_length": 36, "reference_length": 8658}
{"bleu": 0.0, "precisions": [0.15, 0.0, 0.0, 0.0], "brevity_penalty": 0.5769498103804866, "length_ratio": 0.6451612903225806, "translation_length": 20, "reference_length": 31}
{"bleu": 0.0, "precisions": [0.20018365472910926, 0.0009191176470588235, 0.0, 0.0], "brevity_penalty": 0.03454567522710446, "length_ratio": 0.22907025662599917, "translation_length": 1089, "reference_length": 4754}
{"bleu": 0.02161886060751086, "precisions": [0.044284243048403706, 0.02268041237113402, 0.017543859649122806, 0.012396694214876033], "brevity_penalty": 1.0, "length_ratio": 9.160377358490566, "translation_length": 971, "reference_length": 106}
{"bleu": 0.27078920476784707, "precisions": [0.3490136570561457, 0.2735562310030395, 0.2496194824961948, 0.22560975609756098], "brevity_penalty": 1.0, "length_ratio": 1.1001669449081803, "translation_length": 659, "reference_length": 599}
{"bleu": 0.0, "precisions": [0.0029910269192422734, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 71.64285714285714, "translation_length": 1003, "reference_length": 14}
{"bleu": 0.013992305881393672, "precisions": [0.07190412782956059, 0.018666666666666668, 0.010680907877169559, 0.00267379679144385], "brevity_penalty": 1.0, "length_ratio": 4.908496732026144, "translation_length": 751, "reference_length": 153}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 0.4493289641172217, "length_ratio": 0.5555555555555556, "translation_length": 10, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.0014484356894553883, 0.0002897291032884253, 0.0001448855404230658, 0.0], "brevity_penalty": 1.0, "length_ratio": 197.25714285714287, "translation_length": 6904, "reference_length": 35}
{"bleu": 0.05742874514484352, "precisions": [0.9776902887139107, 0.9513797634691196, 0.9263157894736842, 0.9011857707509882], "brevity_penalty": 0.06117826775358215, "length_ratio": 0.26357661708751295, "translation_length": 762, "reference_length": 2891}
{"bleu": 0.0, "precisions": [0.10719754977029096, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.1894353369763206, "translation_length": 653, "reference_length": 549}
{"bleu": 0.0, "precisions": [0.012477718360071301, 0.0, 0.0, 0.0], "brevity_penalty": 0.0006177151890027683, "length_ratio": 0.11919685541272708, "translation_length": 1122, "reference_length": 9413}
{"bleu": 0.0, "precisions": [0.058823529411764705, 0.0, 0.0, 0.0], "brevity_penalty": 0.49367278838913026, "length_ratio": 0.5862068965517241, "translation_length": 17, "reference_length": 29}
{"bleu": 0.006100883703252318, "precisions": [0.0794392523364486, 0.021052631578947368, 0.01639344262295082, 0.012895662368112544], "brevity_penalty": 0.2501951617436665, "length_ratio": 0.41919686581782567, "translation_length": 856, "reference_length": 2042}
{"bleu": 0.010561908734412581, "precisions": [0.06168446026097272, 0.011876484560570071, 0.0047562425683709865, 0.0035714285714285713], "brevity_penalty": 1.0, "length_ratio": 6.637795275590551, "translation_length": 843, "reference_length": 127}
{"bleu": 0.0, "precisions": [0.14285714285714285, 0.0, 0.0, 0.0], "brevity_penalty": 0.25133906849616483, "length_ratio": 0.42, "translation_length": 21, "reference_length": 50}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.0, "translation_length": 24, "reference_length": 8}
{"bleu": 0.0, "precisions": [0.07692307692307693, 0.0, 0.0, 0.0], "brevity_penalty": 5.547604783137187e-26, "length_ratio": 0.016905071521456438, "translation_length": 13, "reference_length": 769}
{"bleu": 0.041025196918641475, "precisions": [0.06389452332657201, 0.04060913705583756, 0.03353658536585366, 0.03255340793489318], "brevity_penalty": 1.0, "length_ratio": 3.8515625, "translation_length": 986, "reference_length": 256}
{"bleu": 0.12193951969929238, "precisions": [0.9572192513368984, 0.9236947791164659, 0.9048257372654156, 0.8926174496644296], "brevity_penalty": 0.13264837139465618, "length_ratio": 0.33111996458610005, "translation_length": 748, "reference_length": 2259}
{"bleu": 0.0, "precisions": [0.004766444232602479, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 61.705882352941174, "translation_length": 1049, "reference_length": 17}
{"bleu": 0.0, "precisions": [0.07692307692307693, 0.0, 0.0, 0.0], "brevity_penalty": 0.5404329964865341, "length_ratio": 0.6190476190476191, "translation_length": 13, "reference_length": 21}
{"bleu": 0.13303437989261152, "precisions": [0.29441624365482233, 0.15593220338983052, 0.12563667232597622, 0.09523809523809523], "brevity_penalty": 0.8689758607306973, "length_ratio": 0.8768545994065282, "translation_length": 591, "reference_length": 674}
{"bleu": 0.028395945550468003, "precisions": [0.14381591562799617, 0.03262955854126679, 0.01440922190201729, 0.009615384615384616], "brevity_penalty": 1.0, "length_ratio": 2.5753086419753086, "translation_length": 1043, "reference_length": 405}
{"bleu": 0.012930520588209825, "precisions": [0.022244191794364803, 0.012858555885262116, 0.010390895596239486, 0.009405940594059406], "brevity_penalty": 1.0, "length_ratio": 5.38031914893617, "translation_length": 2023, "reference_length": 376}
{"bleu": 0.0, "precisions": [0.037241379310344824, 0.0055248618784530384, 0.0027662517289073307, 0.0], "brevity_penalty": 1.0, "length_ratio": 11.885245901639344, "translation_length": 725, "reference_length": 61}
{"error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 274.69 MiB is free. Including non-PyTorch memory, this process has 10.47 GiB memory in use. Of the allocated memory 10.04 GiB is allocated by PyTorch, and 231.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 12.69 MiB is free. Including non-PyTorch memory, this process has 10.73 GiB memory in use. Of the allocated memory 10.43 GiB is allocated by PyTorch, and 99.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.21189979123173278, 0.003134796238244514, 0.0, 0.0], "brevity_penalty": 0.3448250255795695, "length_ratio": 0.48432760364004046, "translation_length": 958, "reference_length": 1978}
{"bleu": 0.048079831173912235, "precisions": [0.055379746835443035, 0.05071315372424723, 0.046031746031746035, 0.04133545310015898], "brevity_penalty": 1.0, "length_ratio": 18.057142857142857, "translation_length": 632, "reference_length": 35}
{"bleu": 0.077735212106618, "precisions": [0.18306351183063513, 0.08354114713216958, 0.056179775280898875, 0.0425], "brevity_penalty": 1.0, "length_ratio": 2.102094240837696, "translation_length": 803, "reference_length": 382}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 0.08677432947392927, "length_ratio": 0.2903225806451613, "translation_length": 9, "reference_length": 31}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.0769230769230769, "translation_length": 42, "reference_length": 39}
{"bleu": 0.0, "precisions": [0.21739130434782608, 0.0, 0.0, 0.0], "brevity_penalty": 3.3428204802123657e-06, "length_ratio": 0.07348242811501597, "translation_length": 23, "reference_length": 313}
{"bleu": 0.0, "precisions": [0.1864406779661017, 0.0, 0.0, 0.0], "brevity_penalty": 9.815774063096941e-22, "length_ratio": 0.020254033642293168, "translation_length": 59, "reference_length": 2913}
{"bleu": 0.0, "precisions": [0.1, 0.0, 0.0, 0.0], "brevity_penalty": 8.29381916075737e-06, "length_ratio": 0.07874015748031496, "translation_length": 10, "reference_length": 127}
{"bleu": 0.0, "precisions": [0.1, 0.0, 0.0, 0.0], "brevity_penalty": 0.036883167401240015, "length_ratio": 0.23255813953488372, "translation_length": 10, "reference_length": 43}
{"bleu": 0.03838463514725478, "precisions": [0.04083885209713024, 0.03867403314917127, 0.03761061946902655, 0.036544850498338874], "brevity_penalty": 1.0, "length_ratio": 21.069767441860463, "translation_length": 906, "reference_length": 43}
{"bleu": 0.1302853196657505, "precisions": [0.2978723404255319, 0.16129032258064516, 0.13043478260869565, 0.0989010989010989], "brevity_penalty": 0.8257284094045387, "length_ratio": 0.8392857142857143, "translation_length": 94, "reference_length": 112}
{"bleu": 2.9480112222630955e-06, "precisions": [0.4851104707012488, 0.29423076923076924, 0.17709335899903753, 0.08092485549132948], "brevity_penalty": 1.3862000062874214e-05, "length_ratio": 0.08205896263597667, "translation_length": 1041, "reference_length": 12686}
{"error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"}
