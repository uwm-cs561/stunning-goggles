{"bleu": 0.0, "precisions": [0.004142502071251036, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 67.05555555555556, "translation_length": 1207, "reference_length": 18}
{"bleu": 0.0, "precisions": [0.4411764705882353, 0.0, 0.0, 0.0], "brevity_penalty": 8.709743203983368e-09, "length_ratio": 0.05112781954887218, "translation_length": 34, "reference_length": 665}
{"bleu": 0.20250030070396946, "precisions": [0.37823834196891193, 0.22916666666666666, 0.16753926701570682, 0.11578947368421053], "brevity_penalty": 1.0, "length_ratio": 1.8037383177570094, "translation_length": 193, "reference_length": 107}
{"bleu": 0.0, "precisions": [0.4166666666666667, 0.0, 0.0, 0.0], "brevity_penalty": 6.033249137014046e-115, "length_ratio": 0.003787878787878788, "translation_length": 12, "reference_length": 3168}
{"bleu": 0.07128947344816641, "precisions": [0.2502708559046587, 0.08134490238611713, 0.04668838219326819, 0.02717391304347826], "brevity_penalty": 1.0, "length_ratio": 1.883673469387755, "translation_length": 923, "reference_length": 490}
{"bleu": 0.0, "precisions": [0.2631578947368421, 0.0, 0.0, 0.0], "brevity_penalty": 2.611735571603125e-11, "length_ratio": 0.03941908713692946, "translation_length": 19, "reference_length": 482}
{"bleu": 0.18148810037050597, "precisions": [0.3724832214765101, 0.226890756302521, 0.1936026936026936, 0.16188870151770657], "brevity_penalty": 0.7999913511652337, "length_ratio": 0.8175582990397805, "translation_length": 596, "reference_length": 729}
{"bleu": 0.006203400695686625, "precisions": [0.038752362948960305, 0.008514664143803218, 0.004734848484848485, 0.0009478672985781991], "brevity_penalty": 1.0, "length_ratio": 7.666666666666667, "translation_length": 1058, "reference_length": 138}
{"bleu": 0.007733127372133742, "precisions": [0.06130268199233716, 0.010546500479386385, 0.005758157389635317, 0.0009606147934678194], "brevity_penalty": 1.0, "length_ratio": 6.649681528662421, "translation_length": 1044, "reference_length": 157}
{"bleu": 0.0, "precisions": [0.006355932203389831, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 16.56140350877193, "translation_length": 944, "reference_length": 57}
{"bleu": 0.0027152656289041, "precisions": [0.004093118444614991, 0.0028147389969293756, 0.002303557716918352, 0.002048131080389145], "brevity_penalty": 1.0, "length_ratio": 114.97058823529412, "translation_length": 3909, "reference_length": 34}
{"bleu": 0.01391155134775051, "precisions": [0.22341696535244923, 0.0215311004784689, 0.01437125748502994, 0.01079136690647482], "brevity_penalty": 0.47335521013775184, "length_ratio": 0.5721120984278879, "translation_length": 837, "reference_length": 1463}
{"bleu": 0.05906843063239191, "precisions": [0.6167076167076168, 0.3836065573770492, 0.34618539786710417, 0.34318555008210183], "brevity_penalty": 0.14426290193286143, "length_ratio": 0.34058577405857743, "translation_length": 1221, "reference_length": 3585}
{"bleu": 0.0009026854698712102, "precisions": [0.9220462850182704, 0.7865853658536586, 0.7081807081807082, 0.6308068459657702], "brevity_penalty": 0.0011964696406996443, "length_ratio": 0.12939322301024428, "translation_length": 821, "reference_length": 6345}
{"bleu": 0.0, "precisions": [0.038797284190106696, 0.000970873786407767, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.5861538461538462, "translation_length": 1031, "reference_length": 650}
{"bleu": 0.0, "precisions": [0.04407443682664055, 0.00196078431372549, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.4781553398058254, "translation_length": 1021, "reference_length": 412}
{"bleu": 0.11990744501374691, "precisions": [0.9311163895486936, 0.8632580261593341, 0.8226190476190476, 0.7854588796185935], "brevity_penalty": 0.1412470695694249, "length_ratio": 0.3381526104417671, "translation_length": 842, "reference_length": 2490}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 0.06392786120670757, "length_ratio": 0.26666666666666666, "translation_length": 8, "reference_length": 30}
{"bleu": 0.0, "precisions": [0.5977011494252874, 0.1636828644501279, 0.06658130601792574, 0.0], "brevity_penalty": 0.0003566708044408626, "length_ratio": 0.11187312473210459, "translation_length": 783, "reference_length": 6999}
{"error": "CUDA out of memory. Tried to allocate 226.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 158.69 MiB is free. Including non-PyTorch memory, this process has 10.59 GiB memory in use. Of the allocated memory 10.29 GiB is allocated by PyTorch, and 95.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 18.69 MiB is free. Including non-PyTorch memory, this process has 10.72 GiB memory in use. Of the allocated memory 10.39 GiB is allocated by PyTorch, and 130.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 3.0476190476190474, "translation_length": 512, "reference_length": 168}
{"bleu": 0.014334889916501668, "precisions": [0.04777777777777778, 0.017797552836484983, 0.011135857461024499, 0.004459308807134894], "brevity_penalty": 1.0, "length_ratio": 9.89010989010989, "translation_length": 900, "reference_length": 91}
{"bleu": 0.0, "precisions": [0.07692307692307693, 0.0, 0.0, 0.0], "brevity_penalty": 1.7320500046289415e-28, "length_ratio": 0.015402843601895734, "translation_length": 13, "reference_length": 844}
{"bleu": 0.0, "precisions": [0.25, 0.0, 0.0, 0.0], "brevity_penalty": 0.0008047330101246132, "length_ratio": 0.12307692307692308, "translation_length": 8, "reference_length": 65}
{"bleu": 0.0, "precisions": [0.15, 0.0, 0.0, 0.0], "brevity_penalty": 0.8187307530779819, "length_ratio": 0.8333333333333334, "translation_length": 20, "reference_length": 24}
{"bleu": 0.0, "precisions": [0.12, 0.0, 0.0, 0.0], "brevity_penalty": 0.3985190410845142, "length_ratio": 0.5208333333333334, "translation_length": 25, "reference_length": 48}
{"bleu": 0.01326277767136418, "precisions": [0.08959537572254335, 0.011571841851494697, 0.007722007722007722, 0.003864734299516908], "brevity_penalty": 1.0, "length_ratio": 3.0262390670553936, "translation_length": 1038, "reference_length": 343}
{"bleu": 0.7548694465000921, "precisions": [0.8782505910165485, 0.8331360946745562, 0.79739336492891, 0.763938315539739], "brevity_penalty": 0.9238586294338812, "length_ratio": 0.9266155531215772, "translation_length": 846, "reference_length": 913}
{"bleu": 0.017337587290563602, "precisions": [0.41872791519434627, 0.22281167108753316, 0.20353982300884957, 0.18511957484499558], "brevity_penalty": 0.0712025854723288, "length_ratio": 0.27455736114479745, "translation_length": 1132, "reference_length": 4123}
{"bleu": 0.0, "precisions": [0.006147540983606557, 0.0010256410256410256, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 21.68888888888889, "translation_length": 976, "reference_length": 45}
{"bleu": 0.0, "precisions": [0.3, 0.0, 0.0, 0.0], "brevity_penalty": 4.248354255291589e-18, "length_ratio": 0.024390243902439025, "translation_length": 10, "reference_length": 410}
{"bleu": 0.0, "precisions": [0.25, 0.0, 0.0, 0.0], "brevity_penalty": 7.991959892953932e-11, "length_ratio": 0.041237113402061855, "translation_length": 4, "reference_length": 97}
{"bleu": 0.0, "precisions": [0.05064935064935065, 0.0, 0.0, 0.0], "brevity_penalty": 0.2965366629971733, "length_ratio": 0.451348182883939, "translation_length": 770, "reference_length": 1706}
{"bleu": 0.0054228966888139035, "precisions": [0.9970873786407767, 0.8736637512147716, 0.8375486381322957, 0.8062317429406037], "brevity_penalty": 0.00619219271833164, "length_ratio": 0.1643529599489389, "translation_length": 1030, "reference_length": 6267}
{"bleu": 0.0, "precisions": [0.3505654281098546, 0.13592233009708737, 0.06807131280388978, 0.0], "brevity_penalty": 0.2207993722277981, "length_ratio": 0.3983268983268983, "translation_length": 619, "reference_length": 1554}
{"bleu": 0.15041900646168094, "precisions": [0.16094674556213018, 0.1504739336492891, 0.14709371293001186, 0.14370546318289787], "brevity_penalty": 1.0, "length_ratio": 6.1231884057971016, "translation_length": 845, "reference_length": 138}
{"bleu": 0.0, "precisions": [0.3413173652694611, 0.018072289156626505, 0.006060606060606061, 0.0], "brevity_penalty": 0.4222002932036978, "length_ratio": 0.5369774919614148, "translation_length": 167, "reference_length": 311}
{"bleu": 1.5414633373325209e-06, "precisions": [0.9779735682819384, 0.9349503858875413, 0.9083885209713024, 0.8861878453038674], "brevity_penalty": 1.6641977193802572e-06, "length_ratio": 0.06989992301770592, "translation_length": 908, "reference_length": 12990}
{"bleu": 0.0, "precisions": [0.2, 0.0, 0.0, 0.0], "brevity_penalty": 0.016572675401761255, "length_ratio": 0.19607843137254902, "translation_length": 10, "reference_length": 51}
{"bleu": 0.0, "precisions": [0.06666666666666667, 0.0, 0.0, 0.0], "brevity_penalty": 0.6703200460356393, "length_ratio": 0.7142857142857143, "translation_length": 15, "reference_length": 21}
{"bleu": 0.0, "precisions": [0.16989737742303307, 0.0, 0.0, 0.0], "brevity_penalty": 0.00021235724301562318, "length_ratio": 0.10573908849770919, "translation_length": 877, "reference_length": 8294}
{"error": "CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 10.75 GiB of which 156.69 MiB is free. Including non-PyTorch memory, this process has 10.59 GiB memory in use. Of the allocated memory 10.16 GiB is allocated by PyTorch, and 229.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"}
{"bleu": 0.17085611396479522, "precisions": [0.1750841750841751, 0.17229729729729729, 0.1694915254237288, 0.16666666666666666], "brevity_penalty": 1.0, "length_ratio": 5.033898305084746, "translation_length": 297, "reference_length": 59}
{"bleu": 0.004703829607552013, "precisions": [0.40611620795107034, 0.13769889840881272, 0.1316595223515003, 0.12806372549019607], "brevity_penalty": 0.026843354238518483, "length_ratio": 0.2165562913907285, "translation_length": 1635, "reference_length": 7550}
{"bleu": 0.0, "precisions": [0.0003255208333333333, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 2.3063063063063063, "translation_length": 3072, "reference_length": 1332}
{"bleu": 0.0, "precisions": [0.18487394957983194, 0.025423728813559324, 0.008547008547008548, 0.0], "brevity_penalty": 0.9833337223669275, "length_ratio": 0.9834710743801653, "translation_length": 119, "reference_length": 121}
{"bleu": 0.0, "precisions": [0.4309500489715965, 0.00196078431372549, 0.0, 0.0], "brevity_penalty": 0.0004522509823697183, "length_ratio": 0.11492570914002702, "translation_length": 1021, "reference_length": 8884}
{"bleu": 0.03963449710047971, "precisions": [0.2601726263871763, 0.03827160493827161, 0.022249690976514216, 0.011138613861386138], "brevity_penalty": 1.0, "length_ratio": 1.4353982300884955, "translation_length": 811, "reference_length": 565}
{"bleu": 0.3834567864001215, "precisions": [0.384526558891455, 0.3838150289017341, 0.38310185185185186, 0.3823870220162225], "brevity_penalty": 1.0, "length_ratio": 2.5470588235294116, "translation_length": 866, "reference_length": 340}
{"bleu": 5.968407873690272e-05, "precisions": [0.5852842809364549, 0.2897822445561139, 0.21644295302013422, 0.20168067226890757], "brevity_penalty": 0.00020346836901064417, "length_ratio": 0.10526315789473684, "translation_length": 598, "reference_length": 5681}
{"bleu": 0.0, "precisions": [0.0199468085106383, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 13.192982456140351, "translation_length": 752, "reference_length": 57}
{"bleu": 0.0011781186182756773, "precisions": [0.896551724137931, 0.8245614035087719, 0.8214285714285714, 0.8181818181818182], "brevity_penalty": 0.0014032482977192804, "length_ratio": 0.13211845102505695, "translation_length": 58, "reference_length": 439}
{"bleu": 0.0, "precisions": [0.019715224534501644, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 7.939130434782609, "translation_length": 913, "reference_length": 115}
{"bleu": 0.0, "precisions": [0.125, 0.0, 0.0, 0.0], "brevity_penalty": 0.0011708796207911744, "length_ratio": 0.12903225806451613, "translation_length": 8, "reference_length": 62}
{"bleu": 0.33815561453031523, "precisions": [0.5085995085995086, 0.4440344403444034, 0.4408866995073892, 0.43773119605425403], "brevity_penalty": 0.7400905014665101, "length_ratio": 0.7686496694995278, "translation_length": 814, "reference_length": 1059}
{"bleu": 0.0, "precisions": [0.31633986928104574, 0.017015706806282723, 0.0, 0.0], "brevity_penalty": 0.30396288519530734, "length_ratio": 0.4564439140811456, "translation_length": 765, "reference_length": 1676}
{"bleu": 9.056390276991312e-69, "precisions": [0.5714285714285714, 0.25925925925925924, 0.23076923076923078, 0.2], "brevity_penalty": 3.149409248288149e-68, "length_ratio": 0.006392694063926941, "translation_length": 28, "reference_length": 4380}
{"bleu": 0.0, "precisions": [0.375, 0.0, 0.0, 0.0], "brevity_penalty": 4.161262970056734e-39, "length_ratio": 0.011188811188811189, "translation_length": 8, "reference_length": 715}
{"bleu": 0.0, "precisions": [0.391304347826087, 0.045454545454545456, 0.0, 0.0], "brevity_penalty": 2.7829127483359325e-36, "length_ratio": 0.012067156348373556, "translation_length": 23, "reference_length": 1906}
{"bleu": 0.0030497436138698653, "precisions": [0.9027777777777778, 0.8450704225352113, 0.8428571428571429, 0.8405797101449275], "brevity_penalty": 0.003556818231724972, "length_ratio": 0.1506276150627615, "translation_length": 72, "reference_length": 478}
{"bleu": 0.3107348764250831, "precisions": [0.8528183716075156, 0.7345872518286312, 0.7165271966527197, 0.7015706806282722], "brevity_penalty": 0.41480023074509503, "length_ratio": 0.5319267073847862, "translation_length": 958, "reference_length": 1801}
{"bleu": 0.0, "precisions": [0.2857142857142857, 0.0, 0.0, 0.0], "brevity_penalty": 1.6507419337718225e-06, "length_ratio": 0.06986027944111776, "translation_length": 35, "reference_length": 501}
{"bleu": 0.08680257318401176, "precisions": [0.991304347826087, 0.9817232375979112, 0.9790940766550522, 0.976460331299041], "brevity_penalty": 0.08838199942195084, "length_ratio": 0.2918781725888325, "translation_length": 1150, "reference_length": 3940}
{"bleu": 0.8318071540745801, "precisions": [0.9686274509803922, 0.9645669291338582, 0.9644268774703557, 0.9642857142857143], "brevity_penalty": 0.8615522215525229, "length_ratio": 0.8703071672354948, "translation_length": 255, "reference_length": 293}
{"bleu": 0.0, "precisions": [0.0, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 1.4285714285714286, "translation_length": 10, "reference_length": 7}
{"bleu": 0.6858544034878273, "precisions": [0.9988095238095238, 0.9976162097735399, 0.9976133651551312, 0.997610513739546], "brevity_penalty": 0.6872892787909722, "length_ratio": 0.7272727272727273, "translation_length": 840, "reference_length": 1155}
{"bleu": 0.0, "precisions": [0.17391304347826086, 0.0, 0.0, 0.0], "brevity_penalty": 0.41913374169932255, "length_ratio": 0.5348837209302325, "translation_length": 23, "reference_length": 43}
{"bleu": 0.0, "precisions": [0.004906771344455349, 0.0, 0.0, 0.0], "brevity_penalty": 1.0, "length_ratio": 36.392857142857146, "translation_length": 1019, "reference_length": 28}
{"bleu": 0.049938575758490346, "precisions": [0.05892116182572614, 0.05149501661129568, 0.04738154613466334, 0.04326123128119801], "brevity_penalty": 1.0, "length_ratio": 14.518072289156626, "translation_length": 1205, "reference_length": 83}
{"bleu": 0.0, "precisions": [0.058823529411764705, 0.0, 0.0, 0.0], "brevity_penalty": 0.7903383629814982, "length_ratio": 0.8095238095238095, "translation_length": 17, "reference_length": 21}
{"error": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"}
